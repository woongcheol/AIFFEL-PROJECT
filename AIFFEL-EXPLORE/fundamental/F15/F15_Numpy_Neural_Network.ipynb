{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attractive-volunteer",
   "metadata": {},
   "source": [
    "# F15. Numpy and Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-photograph",
   "metadata": {},
   "source": [
    "## 1. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-consideration",
   "metadata": {},
   "source": [
    "### 1-1. Layer Perceptron : MNSIT Revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "following-arbitration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.8413 - accuracy: 0.8086\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2443 - accuracy: 0.9309\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1864 - accuracy: 0.9472\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1545 - accuracy: 0.9561\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1307 - accuracy: 0.9619\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1121 - accuracy: 0.9680\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1016 - accuracy: 0.9719\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0944 - accuracy: 0.9723\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0832 - accuracy: 0.9761\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0792 - accuracy: 0.9781\n",
      "313/313 - 0s - loss: 0.1041 - accuracy: 0.9699\n",
      "test_loss: 0.10410431027412415 \n",
      "test_accuracy: 0.9699000120162964\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터를 로드 및 다운로드\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "# 모델에 따른 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# 모델 구성 - 2 Layer Perceptron\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))  # 입력층 d=784, 은닉층 레이어 H=50\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))   # 출력층 레이어 K=10\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성 및 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ruled-review",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# MNIST 손글씨 분류기 Numpy 변경\n",
    "print(x_train_reshaped.shape) # 입력층 데이터 모양(shape)\n",
    "\n",
    "X = x_train_reshaped[:5] # 테스트 목적 x_train_reshaped 앞 5개의 데이터 확인\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "lonely-partnership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_reshaped.shape : (60000, 784)\n",
      "X.shape : (5, 784)\n",
      "W1.shape : (784, 50)\n",
      "b1.shape : (50,)\n",
      "a1.shape : (5, 50)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shape)\n",
    "print(\"x_train_reshaped.shape :\", x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(\"X.shape :\", X.shape)\n",
    "\n",
    "weight_init_std = 0.1\n",
    "input_size = 784 # 입력층 노드수\n",
    "hidden_size=50 # 히든층 노드수\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  \n",
    "\n",
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X, W1) + b1 # 은닉층 출력\n",
    "\n",
    "print(\"W1.shape :\", W1.shape)\n",
    "print(\"b1.shape :\", b1.shape)\n",
    "print(\"a1.shape :\", a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "second-adoption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트용 x_train_reshaped 출력\n",
    "# 입력값에 입력층 레이어의 개수만큼의 열이 있음(784)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "trained-inspiration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.random.randn(input_size, hidden_size) : [[ 1.46852147  0.14546207 -0.88055115 ...  1.78349241 -0.17150591\n",
      "   0.39996361]\n",
      " [ 0.06080134  1.66066836 -0.03162674 ...  1.13232375 -0.21847511\n",
      "  -2.57227503]\n",
      " [-0.59128061 -0.42132061 -0.81623952 ...  0.19362163  2.25858619\n",
      "  -1.79941709]\n",
      " ...\n",
      " [ 0.12531991 -0.17262027  0.2903992  ...  0.98284371  1.35261059\n",
      "   1.7447601 ]\n",
      " [-0.74791104  0.37025822  0.86461611 ...  0.30672621  1.10000301\n",
      "   1.47225122]\n",
      " [-1.24469354  0.22047195  0.07378312 ... -1.76859392 -1.14159812\n",
      "   0.3544597 ]]\n",
      "W1 : [[-0.058353   -0.06140181 -0.06166726 ... -0.08292179 -0.0150748\n",
      "   0.15476538]\n",
      " [ 0.09935193 -0.0155833  -0.09983189 ... -0.00722338  0.01032683\n",
      "  -0.04607381]\n",
      " [ 0.25900173 -0.03441765  0.12989731 ...  0.09742154 -0.04093246\n",
      "   0.04199378]\n",
      " ...\n",
      " [ 0.08735813  0.11964248 -0.16612806 ... -0.0092834  -0.20651865\n",
      "   0.14851002]\n",
      " [-0.0052667   0.16367941  0.06620925 ...  0.12243768  0.03071117\n",
      "  -0.09150339]\n",
      " [ 0.15080454 -0.11182861  0.03479277 ... -0.03066873 -0.04096794\n",
      "   0.10201194]]\n"
     ]
    }
   ],
   "source": [
    "# W1은 레이어 관계로, (784, 50) 행렬로 입력층과 은닉층의 레이어 수가 적용\n",
    "# W1을 구성하는 weight_init_std를 곱하는 것은 가중치?\n",
    "# np.random.randn(input_size, hidden_size))는 가우시안 분포로 난수 적용(랜덤)\n",
    "\n",
    "print(\"np.random.randn(input_size, hidden_size) :\", np.random.randn(input_size, hidden_size))  \n",
    "print(\"W1 :\", W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "judicial-covering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.64692905,  1.60314145,  0.27041901,  0.32223896,  0.16596337,\n",
       "        0.78899029, -0.12837848, -0.23048789,  1.68618408, -1.64646846,\n",
       "        0.99940115, -1.28517841, -0.10105653, -1.14186393,  0.3477459 ,\n",
       "       -0.00715804,  0.6839424 , -0.27001866,  0.26572436,  1.06299018,\n",
       "        1.41952307,  0.37365666,  0.71918499, -0.34692995,  1.17961416,\n",
       "       -0.74371378, -0.88602321,  0.85120816, -0.04243581,  1.74786874,\n",
       "       -0.02220419, -0.50920799, -0.00655761,  0.04193718, -1.26184178,\n",
       "        0.7351617 , -0.19759718, -0.76120202,  0.50454569,  0.25862719,\n",
       "       -0.02996498, -0.33979586,  0.13636333, -0.94732093, -0.12519037,\n",
       "       -0.77687384,  0.85069968, -1.29950343,  0.59978267,  1.53386279])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 데이터 은닉층 출력\n",
    "a1[0] # 50dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-december",
   "metadata": {},
   "source": [
    "### 1-2. Activation Functions and Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-precipitation",
   "metadata": {},
   "source": [
    "#### 1-2-1. Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "challenging-player",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49139551 0.45880814 0.55579686 0.5550321  0.41944501 0.45059766\n",
      " 0.3669098  0.61058032 0.60820968 0.56727145 0.8307918  0.7376851\n",
      " 0.26492062 0.79409077 0.69742382 0.49220668 0.62815478 0.27015655\n",
      " 0.53803194 0.62420004 0.37213348 0.51802744 0.65309224 0.58435402\n",
      " 0.57567632 0.58654954 0.26704442 0.78267951 0.12772931 0.70575652\n",
      " 0.57492988 0.40890373 0.50659121 0.2522381  0.58192214 0.35712419\n",
      " 0.32568425 0.75365604 0.41268275 0.65990378 0.53666129 0.44602912\n",
      " 0.63483209 0.191191   0.18257856 0.35357597 0.66088587 0.54921061\n",
      " 0.60522611 0.67026645]\n"
     ]
    }
   ],
   "source": [
    "# 위 수식의 sigmoid 함수를 구현해 봅니다.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])  # sigmoid의 출력은 모든 element가 0에서 1사이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "enabling-occurrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go~\n"
     ]
    }
   ],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache\n",
    "\n",
    "print('go~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "thermal-kidney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47374553  0.00913184  0.14091983 -0.33422352 -0.12113985 -1.12871204\n",
      " -0.25727274  0.19947448  0.34541859  0.10409944]\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
    "\n",
    "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "further-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "broad-found",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0675003 , 0.10939984, 0.12481061, 0.07760673, 0.09603741,\n",
       "       0.03506367, 0.0838144 , 0.13233705, 0.15313138, 0.12029861])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-vacuum",
   "metadata": {},
   "source": [
    "#### 1-2-2. Tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-ghost",
   "metadata": {},
   "source": [
    "#### 1-2-3. ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-dividend",
   "metadata": {},
   "source": [
    "### 1-3. Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-biology",
   "metadata": {},
   "source": [
    "#### 1-3-1. Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "straight-johnson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_ont_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    " \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_ont_hot_label(Y_digit, 10)\n",
    "t     # 정답 라벨의 One-hot 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ruled-crawford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0675003  0.10939984 0.12481061 0.07760673 0.09603741 0.03506367\n",
      " 0.0838144  0.13233705 0.15313138 0.12029861]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "rubber-still",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4880986061739505"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-massachusetts",
   "metadata": {},
   "source": [
    "#### 1-3-2. Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-coaching",
   "metadata": {},
   "source": [
    "### 1-4. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "yellow-fifty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01350006,  0.02187997,  0.02496212,  0.01552135,  0.01920748,\n",
       "        -0.19298727,  0.01676288,  0.02646741,  0.03062628,  0.02405972],\n",
       "       [-0.18731595,  0.02382153,  0.02757819,  0.01428375,  0.01643681,\n",
       "         0.00802808,  0.01376619,  0.02961997,  0.03022884,  0.02355259],\n",
       "       [ 0.01504179,  0.02528016,  0.02302705,  0.01786809, -0.17649223,\n",
       "         0.00726268,  0.01440606,  0.02892093,  0.02445269,  0.02023277],\n",
       "       [ 0.01254741, -0.17560797,  0.02149984,  0.01483544,  0.01992122,\n",
       "         0.00844614,  0.01381669,  0.02577862,  0.03398129,  0.02478133],\n",
       "       [ 0.01222028,  0.02920747,  0.02036246,  0.0150658 ,  0.02001563,\n",
       "         0.00754507,  0.01182567,  0.03024501,  0.02869798, -0.17518537]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num\n",
    "dy    # softmax값의 출력으로 Loss를 미분한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sustained-lambda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02105676, -0.07978616,  0.04608394,  0.03108979, -0.02537567,\n",
       "        -0.06118663,  0.02830438,  0.0559527 ,  0.0609226 , -0.0349482 ],\n",
       "       [-0.04266698, -0.05917842,  0.06058891,  0.04177973, -0.09289945,\n",
       "        -0.01974469,  0.03637418,  0.07563648,  0.077569  , -0.07745876],\n",
       "       [-0.07294141, -0.02792202,  0.0533523 ,  0.03601754, -0.08327801,\n",
       "        -0.00703004,  0.03134849,  0.06597365,  0.06657442, -0.06209492],\n",
       "       [-0.0814575 , -0.08366916,  0.07376566,  0.04790226, -0.02572833,\n",
       "        -0.14114702,  0.04484512,  0.08665618,  0.09438818, -0.01555538],\n",
       "       [-0.0521748 , -0.03219181,  0.056395  ,  0.03777446, -0.02817843,\n",
       "        -0.06179012,  0.03374609,  0.06977469,  0.07268796, -0.09604303],\n",
       "       [-0.11638746, -0.01290194,  0.07584651,  0.04886316, -0.03062177,\n",
       "        -0.1323308 ,  0.04513202,  0.09011812,  0.09449325, -0.06221109],\n",
       "       [-0.04356012, -0.10205822,  0.05029381,  0.03297709, -0.00324925,\n",
       "        -0.07805153,  0.03074561,  0.05962307,  0.06665706, -0.01337752],\n",
       "       [-0.0888801 , -0.04606192,  0.06325966,  0.04142977, -0.05419114,\n",
       "        -0.07543148,  0.03773072,  0.07553451,  0.07939696, -0.03278698],\n",
       "       [-0.03002115, -0.0126393 ,  0.03178481,  0.02140042, -0.03464095,\n",
       "        -0.03343326,  0.01905177,  0.03905033,  0.04010483, -0.04065749],\n",
       "       [-0.08259489, -0.02553891,  0.08291256,  0.05564782, -0.09224779,\n",
       "        -0.09401238,  0.0496806 ,  0.10148173,  0.10407471, -0.09940344],\n",
       "       [-0.09442047, -0.03709252,  0.08236736,  0.05422014, -0.05481657,\n",
       "        -0.12711125,  0.04946736,  0.09909914,  0.10384544, -0.07555863],\n",
       "       [-0.08283139, -0.01923025,  0.05147621,  0.03390738, -0.05775892,\n",
       "        -0.03633954,  0.03025663,  0.0623553 ,  0.06384305, -0.04567846],\n",
       "       [-0.02377513, -0.03876788,  0.04002335,  0.02750587, -0.06123691,\n",
       "        -0.0289661 ,  0.02424824,  0.04941715,  0.05106549, -0.03951408],\n",
       "       [-0.07789798, -0.00893501,  0.06270363,  0.04119967, -0.04858529,\n",
       "        -0.09870476,  0.0375152 ,  0.07543464,  0.07813159, -0.06086171],\n",
       "       [-0.09954735, -0.06503757,  0.05440681,  0.03498742, -0.02856708,\n",
       "        -0.04708592,  0.03206258,  0.0643553 ,  0.06892708, -0.01450127],\n",
       "       [-0.09962825, -0.04129058,  0.06472496,  0.04197073, -0.03028687,\n",
       "        -0.08307878,  0.03840616,  0.07735713,  0.08167017, -0.04984466],\n",
       "       [-0.11373822, -0.07570475,  0.07087812,  0.04631239, -0.02959539,\n",
       "        -0.04398379,  0.04167821,  0.08597768,  0.0909919 , -0.07281614],\n",
       "       [-0.08035544, -0.0655821 ,  0.07223551,  0.04811784, -0.05778313,\n",
       "        -0.06721122,  0.04319725,  0.0879929 ,  0.09236353, -0.07297514],\n",
       "       [-0.06259025, -0.04166381,  0.06859788,  0.04514754, -0.03209761,\n",
       "        -0.13214766,  0.0416752 ,  0.08208501,  0.08731167, -0.05631797],\n",
       "       [-0.00951249, -0.03406347,  0.04086864,  0.02868108, -0.06114141,\n",
       "        -0.02014781,  0.02479265,  0.05188586,  0.05292311, -0.07428616],\n",
       "       [-0.02426398, -0.06728762,  0.05637208,  0.0383509 , -0.05656159,\n",
       "        -0.07419753,  0.03456059,  0.06880555,  0.07300535, -0.04878375],\n",
       "       [-0.00288206, -0.02365207,  0.0259072 ,  0.0181398 , -0.04827256,\n",
       "        -0.02446772,  0.01593817,  0.0321733 ,  0.03306441, -0.02594846],\n",
       "       [-0.06590795, -0.03616366,  0.04847979,  0.03226672, -0.06240357,\n",
       "        -0.03186626,  0.0287692 ,  0.05872592,  0.06067866, -0.03257885],\n",
       "       [-0.06614805, -0.03547115,  0.06397865,  0.04224601, -0.05656498,\n",
       "        -0.10640127,  0.03870155,  0.07641419,  0.08033484, -0.03708979],\n",
       "       [-0.0603599 ,  0.00298453,  0.04331474,  0.02845347, -0.01826253,\n",
       "        -0.05360574,  0.0255482 ,  0.05315174,  0.05448897, -0.07571348],\n",
       "       [-0.0988244 , -0.04217219,  0.06515424,  0.04205559, -0.05899081,\n",
       "        -0.10884868,  0.03908925,  0.07595933,  0.08055056,  0.00602711],\n",
       "       [-0.0901131 , -0.01636188,  0.07426918,  0.04903836, -0.06971557,\n",
       "        -0.10603452,  0.04443952,  0.08951589,  0.09248099, -0.06751886],\n",
       "       [-0.07043041, -0.08218663,  0.07905001,  0.05222654, -0.02725285,\n",
       "        -0.12614106,  0.04793929,  0.09520236,  0.10228771, -0.07069496],\n",
       "       [-0.04364834,  0.00764828,  0.03922207,  0.02659663, -0.06894101,\n",
       "        -0.03049835,  0.02329112,  0.04840449,  0.04796216, -0.05003705],\n",
       "       [-0.12544302, -0.0153112 ,  0.08999182,  0.05870185, -0.07416134,\n",
       "        -0.14368082,  0.05373815,  0.10727469,  0.11138735, -0.06249749],\n",
       "       [-0.03190643, -0.01313579,  0.04321351,  0.02897011, -0.07032899,\n",
       "        -0.08160919,  0.02648096,  0.05129597,  0.05305902, -0.00603917],\n",
       "       [-0.10211474, -0.04750692,  0.04796915,  0.03024483, -0.01473112,\n",
       "        -0.05448603,  0.02812342,  0.05591873,  0.06013802, -0.00355534],\n",
       "       [-0.08976158, -0.04840021,  0.07437463,  0.04904715, -0.04814721,\n",
       "        -0.09313561,  0.04447143,  0.08991097,  0.09439149, -0.07275106],\n",
       "       [-0.07586862, -0.03573319,  0.06177119,  0.04129701, -0.0743495 ,\n",
       "        -0.04687663,  0.03672884,  0.07537238,  0.07753423, -0.0598757 ],\n",
       "       [-0.11748811, -0.0993739 ,  0.06192769,  0.03914227,  0.01008873,\n",
       "        -0.07083255,  0.03658929,  0.07251342,  0.08010134, -0.01266818],\n",
       "       [-0.01147116, -0.07890555,  0.03800531,  0.02577948, -0.02622897,\n",
       "        -0.04973723,  0.02351506,  0.04595956,  0.05052255, -0.01743905],\n",
       "       [-0.0715298 , -0.04761148,  0.05246512,  0.03398762, -0.03503277,\n",
       "        -0.08708542,  0.0315946 ,  0.06151905,  0.06596672, -0.00427365],\n",
       "       [-0.02652247, -0.04592287,  0.05553499,  0.03725583, -0.04994041,\n",
       "        -0.11057493,  0.03425868,  0.06655003,  0.07084268, -0.03148154],\n",
       "       [-0.03254273, -0.02750997,  0.05632611,  0.03764553, -0.057232  ,\n",
       "        -0.11929118,  0.03466445,  0.06725423,  0.07084392, -0.03015837],\n",
       "       [-0.00980402, -0.02433391,  0.04729726,  0.03227028, -0.03984845,\n",
       "        -0.08738506,  0.02914799,  0.05817864,  0.06085804, -0.06638077],\n",
       "       [-0.0743714 , -0.03028656,  0.07581904,  0.05077256, -0.08395028,\n",
       "        -0.09383022,  0.04557112,  0.09227544,  0.09518464, -0.07718432],\n",
       "       [-0.0135694 , -0.02681619,  0.0447625 ,  0.03088911, -0.07488441,\n",
       "        -0.05888001,  0.02748212,  0.05496041,  0.05649681, -0.04044093],\n",
       "       [-0.05989082, -0.00688891,  0.05596623,  0.03681394, -0.07972521,\n",
       "        -0.11689716,  0.03407498,  0.06551346,  0.06798055,  0.00305294],\n",
       "       [ 0.00291106, -0.01749839,  0.0325951 ,  0.02330576, -0.11130678,\n",
       "        -0.03016117,  0.02028694,  0.03992708,  0.03958949,  0.00035091],\n",
       "       [-0.01192276, -0.02205253,  0.0282035 ,  0.01909534, -0.02095177,\n",
       "        -0.04614463,  0.01728005,  0.03452098,  0.03642344, -0.03445162],\n",
       "       [-0.02959784, -0.04282263,  0.04163094,  0.02834487, -0.05738013,\n",
       "        -0.03588534,  0.02521182,  0.05095334,  0.05309044, -0.03354546],\n",
       "       [-0.09974034, -0.03164715,  0.07168574,  0.04654619, -0.05389358,\n",
       "        -0.12130915,  0.04298331,  0.08467788,  0.08914744, -0.02845033],\n",
       "       [-0.02659856, -0.06588042,  0.03934067,  0.02675704, -0.06874659,\n",
       "        -0.03385868,  0.02407443,  0.04710027,  0.05009194,  0.00771991],\n",
       "       [-0.07000386, -0.01094222,  0.04683108,  0.03089177, -0.01585477,\n",
       "        -0.03247711,  0.02736553,  0.05815836,  0.05970217, -0.09367094],\n",
       "       [-0.0248552 , -0.00887432,  0.04592349,  0.03083896, -0.05200468,\n",
       "        -0.09705732,  0.02821824,  0.05519668,  0.05736984, -0.03475569]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2 = np.dot(z1.T, dy)    \n",
    "dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "preceding-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)\n",
    "db2 = np.sum(dy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "statewide-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "controversial-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz1 = np.dot(dy, W2.T)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dW1 = np.dot(X.T, da1)\n",
    "db1 = np.sum(dz1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "alleged-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-brain",
   "metadata": {},
   "source": [
    "### 1-5. Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "committed-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_layer_backward(dy, cache):\n",
    "    X, W, b = cache\n",
    "    dX = np.dot(dy, W.T)\n",
    "    dW = np.dot(X.T, dy)\n",
    "    db = np.sum(dy, axis=0)\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "missing-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04368266 0.05961519 0.12970551 0.09342282 0.09693392 0.1424948\n",
      "  0.07681323 0.04489682 0.16595229 0.14648276]\n",
      " [0.04369926 0.06907336 0.10932632 0.1052114  0.07998448 0.15768372\n",
      "  0.07694194 0.05470809 0.15217881 0.15119262]\n",
      " [0.04641183 0.06060176 0.13999695 0.10511534 0.08237165 0.13521439\n",
      "  0.07115754 0.06081984 0.15436233 0.14394839]\n",
      " [0.04870311 0.05319029 0.13348306 0.10743142 0.0885941  0.15496289\n",
      "  0.07090937 0.05872726 0.14793759 0.13606091]\n",
      " [0.03781398 0.05676919 0.15709204 0.13010145 0.0738811  0.1547007\n",
      "  0.06921221 0.04807552 0.15166367 0.12069014]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.524759214850217\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "# Forward Propagation\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "# 추론과 오차(Loss) 계산\n",
    "y_hat = softmax(a2)\n",
    "t = _change_ont_hot_label(Y_digit, 10)   # 정답 One-hot 인코딩\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "print(y_hat)\n",
    "print(t)\n",
    "print('Loss: ', Loss)\n",
    "        \n",
    "dy = (y_hat - t) / X.shape[0]\n",
    "dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "\n",
    "# 경사하강법을 통한 파라미터 업데이트    \n",
    "learning_rate = 0.1\n",
    "W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "polyphonic-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "def train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=False):\n",
    "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "    z1 = sigmoid(a1)\n",
    "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "    y_hat = softmax(a2)\n",
    "    t = _change_ont_hot_label(Y, 10)\n",
    "    Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "    if verbose:\n",
    "        print('---------')\n",
    "        print(y_hat)\n",
    "        print(t)\n",
    "        print('Loss: ', Loss)\n",
    "        \n",
    "    dy = (y_hat - t) / X.shape[0]\n",
    "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "    da1 = sigmoid_grad(a1) * dz1\n",
    "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "    \n",
    "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    return W1, b1, W2, b2, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "convenient-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "[[0.0748005  0.1208145  0.0646443  0.12730669 0.05449328 0.08290973\n",
      "  0.10223025 0.10275738 0.10123476 0.16880862]\n",
      " [0.07403438 0.11798417 0.07698845 0.12288436 0.04829858 0.08965581\n",
      "  0.10724057 0.10164564 0.0908075  0.17046054]\n",
      " [0.06213008 0.10477289 0.06568848 0.11681943 0.05936269 0.08468967\n",
      "  0.09062493 0.08839979 0.13057952 0.19693253]\n",
      " [0.06733641 0.12297523 0.06392587 0.15076334 0.04635348 0.09682149\n",
      "  0.09682711 0.09877431 0.09794035 0.15828241]\n",
      " [0.05497012 0.11208307 0.07934274 0.12331097 0.04528128 0.10808205\n",
      "  0.08780825 0.09379557 0.09927255 0.1960534 ]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.328491708403848\n",
      "---------\n",
      "[[0.08991605 0.13723375 0.05888309 0.10653981 0.06627266 0.1000039\n",
      "  0.08916981 0.09032971 0.08756626 0.17408495]\n",
      " [0.09269335 0.13294335 0.0701368  0.10288832 0.05825175 0.1040673\n",
      "  0.09403955 0.08877044 0.07854128 0.17766786]\n",
      " [0.07389164 0.11913883 0.06017394 0.09837076 0.07657234 0.09751616\n",
      "  0.0791668  0.07792937 0.11431292 0.20292724]\n",
      " [0.08065852 0.14612518 0.05794839 0.12540714 0.05723842 0.11294087\n",
      "  0.08393934 0.08674586 0.08449192 0.16450437]\n",
      " [0.06591011 0.12712064 0.07149736 0.10202064 0.05527013 0.12385122\n",
      "  0.07594901 0.08185092 0.08470804 0.21182193]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.1451649755983326\n",
      "---------\n",
      "[[0.10417539 0.14989601 0.05323364 0.09046489 0.07784852 0.11605814\n",
      "  0.07796718 0.07939873 0.07603587 0.17492164]\n",
      " [0.11190997 0.14413048 0.0634431  0.08747986 0.06791831 0.11634711\n",
      "  0.08263041 0.07753269 0.06820374 0.18040433]\n",
      " [0.08470424 0.13029012 0.05478079 0.08413918 0.09546023 0.10812164\n",
      "  0.06937871 0.0687761  0.10058803 0.20376095]\n",
      " [0.09295306 0.16649007 0.05205985 0.10574948 0.06816564 0.12649933\n",
      "  0.07280838 0.07607438 0.07306783 0.16613196]\n",
      " [0.07628807 0.13876375 0.06404037 0.08574805 0.06527673 0.13679928\n",
      "  0.06590227 0.07149951 0.07267696 0.22300501]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.997230155251188\n",
      "---------\n",
      "[[0.11724702 0.15910925 0.04799786 0.07774624 0.08891327 0.13084665\n",
      "  0.0684888  0.0699939  0.06638056 0.17327644]\n",
      " [0.13125963 0.15187615 0.05724176 0.07531569 0.07702657 0.1264401\n",
      "  0.07289805 0.06790274 0.05953881 0.18050051]\n",
      " [0.09422278 0.13839183 0.04976315 0.07287559 0.11565384 0.11644029\n",
      "  0.06109243 0.06090104 0.08904386 0.20161521]\n",
      " [0.1038962  0.1839845  0.04662681 0.09027115 0.07882662 0.13743781\n",
      "  0.06340664 0.06689107 0.0635138  0.16514541]\n",
      " [0.08584308 0.14728714 0.05729732 0.07305018 0.07504474 0.14697069\n",
      "  0.0575079  0.0627122  0.06279643 0.23149033]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.875516379836725\n",
      "---------\n",
      "[[0.1289324  0.1654641  0.04328868 0.06751774 0.09918873 0.14436806\n",
      "  0.06050626 0.06198249 0.05830496 0.17044659]\n",
      " [0.15039254 0.15676719 0.05165317 0.06553417 0.08533008 0.13450786\n",
      "  0.06463013 0.05971323 0.05227398 0.17919765]\n",
      " [0.10223853 0.14389409 0.04521388 0.06378433 0.13672207 0.12263775\n",
      "  0.05408727 0.05416391 0.07931251 0.19794566]\n",
      " [0.11331031 0.19895765 0.04178243 0.07792917 0.08893421 0.14598468\n",
      "  0.05553992 0.05910109 0.05556915 0.16289139]\n",
      " [0.0943885  0.15321001 0.05134771 0.06297012 0.08431357 0.15463716\n",
      "  0.05051669 0.0553086  0.0546698  0.23863783]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.773434476976665\n"
     ]
    }
   ],
   "source": [
    "X = x_train_reshaped[:5]\n",
    "Y = y_train[:5]\n",
    "\n",
    "# train_step을 다섯 번 반복 돌립니다.\n",
    "for i in range(5):\n",
    "    W1, b1, W2, b2, _ = train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-sixth",
   "metadata": {},
   "source": [
    "### 1-6. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cardiovascular-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W1, b1, W2, b2, X):\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    y = softmax(a2)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "formal-playing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1391516 , 0.16962041, 0.03912264, 0.0591858 , 0.10844298,\n",
       "       0.15676677, 0.05378442, 0.05518329, 0.05153878, 0.16720331])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = x_train[:100] 에 대해 모델 추론을 시도합니다. \n",
    "X = x_train_reshaped[:100]\n",
    "Y = y_test[:100]\n",
    "result = predict(W1, b1, W2, b2, X)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aquatic-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(W1, b1, W2, b2, x, y):\n",
    "    y_hat = predict(W1, b1, W2, b2, x)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "    accuracy = np.sum(y_hat == y) / float(x.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "handmade-denver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1391516  0.16962041 0.03912264 0.0591858  0.10844298 0.15676677\n",
      " 0.05378442 0.05518329 0.05153878 0.16720331]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "0.09\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(W1, b1, W2, b2, X, Y)\n",
    "\n",
    "t = _change_ont_hot_label(Y, 10)\n",
    "print(result[0])\n",
    "print(t[0])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-captain",
   "metadata": {},
   "source": [
    "## 2. Learning Cycle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "instrumental-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "\n",
    "    W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros(hidden_size)\n",
    "    W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros(output_size)\n",
    "\n",
    "    print(W1.shape)\n",
    "    print(b1.shape)\n",
    "    print(W2.shape)\n",
    "    print(b2.shape)\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "intelligent-straight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(50, 10)\n",
      "(10,)\n",
      "Loss:  2.3045446541689927\n",
      "train acc, test acc | 0.10441666666666667, 0.1028\n",
      "Loss:  0.9141838153063734\n",
      "train acc, test acc | 0.7957666666666666, 0.8002\n",
      "Loss:  0.45542558764508334\n",
      "train acc, test acc | 0.8768166666666667, 0.8829\n",
      "Loss:  0.3915934533357129\n",
      "train acc, test acc | 0.90025, 0.9027\n",
      "Loss:  0.23635944786589466\n",
      "train acc, test acc | 0.9087, 0.9118\n",
      "Loss:  0.3203845303217136\n",
      "train acc, test acc | 0.91565, 0.919\n",
      "Loss:  0.17496475889347318\n",
      "train acc, test acc | 0.9213833333333333, 0.9232\n",
      "Loss:  0.37420104998308873\n",
      "train acc, test acc | 0.9252833333333333, 0.927\n",
      "Loss:  0.3882893863360967\n",
      "train acc, test acc | 0.9288666666666666, 0.9303\n",
      "Loss:  0.15501146674427865\n",
      "train acc, test acc | 0.9324833333333333, 0.9324\n",
      "Loss:  0.12722511255306723\n",
      "train acc, test acc | 0.9349666666666666, 0.9354\n",
      "Loss:  0.21448690163390682\n",
      "train acc, test acc | 0.9374333333333333, 0.9368\n",
      "Loss:  0.11044475785795375\n",
      "train acc, test acc | 0.9401666666666667, 0.9401\n",
      "Loss:  0.23427167879932986\n",
      "train acc, test acc | 0.9420833333333334, 0.9411\n",
      "Loss:  0.16932416889259774\n",
      "train acc, test acc | 0.9434666666666667, 0.9432\n",
      "Loss:  0.17801523445026785\n",
      "train acc, test acc | 0.94515, 0.9441\n",
      "Loss:  0.177301585067533\n",
      "train acc, test acc | 0.9472333333333334, 0.947\n",
      "Loss:  0.13025223088577534\n",
      "train acc, test acc | 0.9482166666666667, 0.9472\n",
      "Loss:  0.06567311414903006\n",
      "train acc, test acc | 0.9492166666666667, 0.9478\n",
      "Loss:  0.21795962170305003\n",
      "train acc, test acc | 0.9505333333333333, 0.9484\n",
      "Loss:  0.07646911679791352\n",
      "train acc, test acc | 0.95255, 0.9492\n",
      "Loss:  0.22498015083449763\n",
      "train acc, test acc | 0.9531833333333334, 0.951\n",
      "Loss:  0.18032713943169018\n",
      "train acc, test acc | 0.95485, 0.9516\n",
      "Loss:  0.22237526522827422\n",
      "train acc, test acc | 0.9565, 0.953\n",
      "Loss:  0.16533603658037405\n",
      "train acc, test acc | 0.9570333333333333, 0.9519\n",
      "Loss:  0.20462640542878036\n",
      "train acc, test acc | 0.9581666666666667, 0.9535\n",
      "Loss:  0.17330819858224847\n",
      "train acc, test acc | 0.9596166666666667, 0.9541\n",
      "Loss:  0.14279223331054167\n",
      "train acc, test acc | 0.96035, 0.955\n",
      "Loss:  0.14396888535774457\n",
      "train acc, test acc | 0.9610333333333333, 0.9563\n",
      "Loss:  0.10044008966815636\n",
      "train acc, test acc | 0.9617833333333333, 0.9564\n",
      "Loss:  0.10177067553754914\n",
      "train acc, test acc | 0.9630333333333333, 0.9571\n",
      "Loss:  0.07353475995847987\n",
      "train acc, test acc | 0.96355, 0.9574\n",
      "Loss:  0.13156639548055765\n",
      "train acc, test acc | 0.9641166666666666, 0.9589\n",
      "Loss:  0.10989961055843825\n",
      "train acc, test acc | 0.9645833333333333, 0.9586\n",
      "Loss:  0.07482353162241025\n",
      "train acc, test acc | 0.9657, 0.9599\n",
      "Loss:  0.0994502620638224\n",
      "train acc, test acc | 0.9663166666666667, 0.9602\n",
      "Loss:  0.13375119057076992\n",
      "train acc, test acc | 0.96705, 0.9607\n",
      "Loss:  0.05389395467586627\n",
      "train acc, test acc | 0.9674166666666667, 0.9598\n",
      "Loss:  0.09687522394839779\n",
      "train acc, test acc | 0.96795, 0.9618\n",
      "Loss:  0.08012296193622052\n",
      "train acc, test acc | 0.9685833333333334, 0.9616\n",
      "Loss:  0.16745966599913711\n",
      "train acc, test acc | 0.9691, 0.9621\n",
      "Loss:  0.05657454786081226\n",
      "train acc, test acc | 0.9698166666666667, 0.9622\n",
      "Loss:  0.04733284853263328\n",
      "train acc, test acc | 0.9700833333333333, 0.9632\n",
      "Loss:  0.09011059937664762\n",
      "train acc, test acc | 0.9708166666666667, 0.9638\n",
      "Loss:  0.09529438430375459\n",
      "train acc, test acc | 0.9715, 0.9649\n",
      "Loss:  0.09567102858248672\n",
      "train acc, test acc | 0.97175, 0.9647\n",
      "Loss:  0.0633953659193125\n",
      "train acc, test acc | 0.9723166666666667, 0.9654\n",
      "Loss:  0.09541475696254301\n",
      "train acc, test acc | 0.9728, 0.9652\n",
      "Loss:  0.13803324382432\n",
      "train acc, test acc | 0.9728166666666667, 0.9655\n",
      "Loss:  0.02725143779121324\n",
      "train acc, test acc | 0.9732166666666666, 0.9649\n",
      "Loss:  0.10855072890556165\n",
      "train acc, test acc | 0.9739166666666667, 0.9657\n",
      "Loss:  0.21552657987120458\n",
      "train acc, test acc | 0.9739166666666667, 0.9663\n",
      "Loss:  0.10053106860521462\n",
      "train acc, test acc | 0.9745166666666667, 0.9669\n",
      "Loss:  0.07272120870787796\n",
      "train acc, test acc | 0.9751333333333333, 0.9665\n",
      "Loss:  0.0967648716782635\n",
      "train acc, test acc | 0.9757666666666667, 0.967\n",
      "Loss:  0.09173633977468137\n",
      "train acc, test acc | 0.9759166666666667, 0.9669\n",
      "Loss:  0.07597604512884065\n",
      "train acc, test acc | 0.9762333333333333, 0.9669\n",
      "Loss:  0.15544625298396442\n",
      "train acc, test acc | 0.9767666666666667, 0.9675\n",
      "Loss:  0.12080135672922365\n",
      "train acc, test acc | 0.9769, 0.9673\n",
      "Loss:  0.06820407588609094\n",
      "train acc, test acc | 0.9770666666666666, 0.9669\n",
      "Loss:  0.05537266398029903\n",
      "train acc, test acc | 0.97735, 0.9673\n",
      "Loss:  0.030001644074884988\n",
      "train acc, test acc | 0.9776333333333334, 0.9678\n",
      "Loss:  0.07660396025740666\n",
      "train acc, test acc | 0.9779, 0.9678\n",
      "Loss:  0.07299103596185086\n",
      "train acc, test acc | 0.9781833333333333, 0.9687\n",
      "Loss:  0.06351995610440989\n",
      "train acc, test acc | 0.97855, 0.9681\n",
      "Loss:  0.1335247785595632\n",
      "train acc, test acc | 0.9786833333333333, 0.9684\n",
      "Loss:  0.11458368362669588\n",
      "train acc, test acc | 0.9788666666666667, 0.9686\n",
      "Loss:  0.08883822362993611\n",
      "train acc, test acc | 0.9794833333333334, 0.9691\n",
      "Loss:  0.12269746088781863\n",
      "train acc, test acc | 0.9792666666666666, 0.9691\n",
      "Loss:  0.09113073482533376\n",
      "train acc, test acc | 0.9800666666666666, 0.9692\n",
      "Loss:  0.03800502824310718\n",
      "train acc, test acc | 0.9800166666666666, 0.9689\n",
      "Loss:  0.018383366358364333\n",
      "train acc, test acc | 0.98005, 0.9693\n",
      "Loss:  0.1185099787526881\n",
      "train acc, test acc | 0.9804166666666667, 0.9695\n",
      "Loss:  0.053101152799400315\n",
      "train acc, test acc | 0.9804166666666667, 0.9694\n",
      "Loss:  0.04030754204777832\n",
      "train acc, test acc | 0.9807166666666667, 0.9699\n",
      "Loss:  0.0601150823328551\n",
      "train acc, test acc | 0.9814333333333334, 0.9706\n",
      "Loss:  0.04446784269137376\n",
      "train acc, test acc | 0.9815666666666667, 0.9693\n",
      "Loss:  0.038017911715327195\n",
      "train acc, test acc | 0.9817833333333333, 0.97\n",
      "Loss:  0.04556052138619406\n",
      "train acc, test acc | 0.9815666666666667, 0.9702\n",
      "Loss:  0.051361343798477684\n",
      "train acc, test acc | 0.98225, 0.9707\n",
      "Loss:  0.0462137512795664\n",
      "train acc, test acc | 0.98245, 0.9705\n",
      "Loss:  0.027189429574236815\n",
      "train acc, test acc | 0.9826333333333334, 0.9708\n",
      "Loss:  0.13237638068991844\n",
      "train acc, test acc | 0.9827833333333333, 0.9708\n",
      "Loss:  0.09916637121303945\n",
      "train acc, test acc | 0.9828, 0.971\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "iters_num = 50000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "W1, b1, W2, b2 = init_params(784, 50, 10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train_reshaped[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    W1, b1, W2, b2, Loss = train_step(x_batch, y_batch, W1, b1, W2, b2, learning_rate=0.1, verbose=False)\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    train_loss_list.append(Loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        print('Loss: ', Loss)\n",
    "        train_acc = accuracy(W1, b1, W2, b2, x_train_reshaped, y_train)\n",
    "        test_acc = accuracy(W1, b1, W2, b2, x_test_reshaped, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "apart-dublin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 6 \n",
    "\n",
    "# Accuracy 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "defensive-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 그래프 그리기\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='train acc')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 3.0)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
