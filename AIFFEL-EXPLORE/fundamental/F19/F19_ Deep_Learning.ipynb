{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infectious-syndrome",
   "metadata": {},
   "source": [
    "# F18. TF2 API\n",
    "## 1. TensorFlow2 Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optical-comfort",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-e0cc2e4ec513>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-e0cc2e4ec513>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    model.add(__넣고싶은 레이어__)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# quential Model 예시 : 1가지의 입력 및 출력이 특징\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(__넣고싶은 레이어__)\n",
    "model.add(__넣고싶은 레이어__)\n",
    "model.add(__넣고싶은 레이어__)\n",
    "\n",
    "model.fit(x, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cutting-hardware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 17s 8ms/step - loss: 0.2031 - accuracy: 0.9355\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0325 - accuracy: 0.9892\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0171 - accuracy: 0.9944\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0116 - accuracy: 0.9964\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0069 - accuracy: 0.9978\n",
      "313/313 - 2s - loss: 0.0475 - accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04747428745031357, 0.9879999756813049]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quential Model 구현하기\n",
    "\n",
    "# 1. tensorflow, keras, numpy 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 2. 데이터 구성\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 3. Model 구성\n",
    "\"\"\"\n",
    "Spec:\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 4. 모델 학습 설정\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5) # 학습\n",
    "model.evaluate(x_test,  y_test, verbose=2) # 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "graduate-retirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 3s 0us/step\n",
      "50000 10000\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 10s 5ms/step - loss: 3.9794 - accuracy: 0.0970\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.9822 - accuracy: 0.2615\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.6235 - accuracy: 0.3419\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3584 - accuracy: 0.4002\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1806 - accuracy: 0.4327\n",
      "313/313 - 1s - loss: 2.5501 - accuracy: 0.3620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5500969886779785, 0.3619999885559082]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quential Model 구현하기(CIFAR-100)\n",
    "\n",
    "# 1. tensorflow, keras, numpy 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 2. 데이터 구성\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 3. Model 구성\n",
    "\"\"\"\n",
    "Spec:\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])\n",
    "\n",
    "# 4. 모델 학습 설정\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5) # 학습\n",
    "model.evaluate(x_test,  y_test, verbose=2) # 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-lighter",
   "metadata": {},
   "source": [
    "## 2. TensorFlow2 Functional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "automated-mining",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-f038360b759f>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-f038360b759f>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    inputs = keras.Input(shape=(__원하는 입력값 모양__))\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Functional API 예시 : 다중 입력과 출력이 특징\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "inputs = keras.Input(shape=(__원하는 입력값 모양__))\n",
    "x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(input)\n",
    "x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
    "outputs = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.fit(x,y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "photographic-while",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2127 - accuracy: 0.9323\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0314 - accuracy: 0.9907\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0169 - accuracy: 0.9945\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0099 - accuracy: 0.9967\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0080 - accuracy: 0.9972\n",
      "313/313 - 2s - loss: 0.0551 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05508102849125862, 0.987500011920929]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functional Model 구현하기\n",
    "'''\n",
    "keras.Model을 직접 활용하고, keras.Input으로 \n",
    "정의된 input 및 output 레이어 구성을 통해 model을 구현\n",
    "'''\n",
    "\n",
    "# 1. tensorflow, keras, numpy 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 2. 데이터 구성\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 3. Model 구성\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. (28X28X1) 차원으로 정의된 Input\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# 4. 모델 학습 설정\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5) # 학습\n",
    "model.evaluate(x_test,  y_test, verbose=2) # 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hired-coordinator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.0186 - accuracy: 0.0933\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.0090 - accuracy: 0.2640\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.6973 - accuracy: 0.3230\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.4775 - accuracy: 0.3687\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3053 - accuracy: 0.4042\n",
      "313/313 - 1s - loss: 2.5975 - accuracy: 0.3524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.597473621368408, 0.352400004863739]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functional Model 구현하기(CIFAR-100)\n",
    "'''\n",
    "keras.Model을 직접 활용하고, keras.Input으로 \n",
    "정의된 input 및 output 레이어 구성을 통해 model을 구현\n",
    "'''\n",
    "\n",
    "# 1. tensorflow, keras, numpy 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 2. 데이터 구성\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 3. Model 구성\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. (32X32X3) 차원으로 정의된 Input\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(inputs)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# 4. 모델 학습 설정\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5) # 학습\n",
    "model.evaluate(x_test,  y_test, verbose=2) # 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-anderson",
   "metadata": {},
   "source": [
    "## 3. TensorFlow2 Subclassing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intended-region",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-2624f4faace1>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-2624f4faace1>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    self.__정의하고자 하는 레이어__()\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Subclassing Model 예시 : 제일 자유로운 모델링 진행\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self): # 메소드 내 레이어 구성을 정의\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "    \n",
    "    def call(self, x): # 메소드 내 레이어 간 forward propagation을 구현\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()\n",
    "model.fit(x,y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "relevant-principle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.2212 - accuracy: 0.9317\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0346 - accuracy: 0.9898\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0114 - accuracy: 0.9963\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0099 - accuracy: 0.9966\n",
      "313/313 - 1s - loss: 0.0484 - accuracy: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04837688431143761, 0.9886000156402588]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subclassing Model 구현하기\n",
    "'''\n",
    "keras.Model을 직접 활용하고, keras.Input으로 \n",
    "정의된 input 및 output 레이어 구성을 통해 model을 구현\n",
    "'''\n",
    "\n",
    "# 1. tensorflow, keras, numpy 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 2. 데이터 구성\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 3. Model 구성\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. keras.Model 을 상속받았으며, __init__()와 call() 메소드를 가진 모델 클래스\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "6. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
    "\"\"\"\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()\n",
    "\n",
    "# 4. 모델 학습 설정\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "labeled-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.0498 - accuracy: 0.0864\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.1079 - accuracy: 0.2434\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.7692 - accuracy: 0.3102\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.5458 - accuracy: 0.3560\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3741 - accuracy: 0.3854\n",
      "313/313 - 1s - loss: 2.6001 - accuracy: 0.3490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.600109577178955, 0.3490000069141388]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subclassing Model 구현하기\n",
    "'''\n",
    "keras.Model을 직접 활용하고, keras.Input으로 \n",
    "정의된 input 및 output 레이어 구성을 통해 model을 구현\n",
    "'''\n",
    "\n",
    "# 1. tensorflow, keras, numpy 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 2. 데이터 구성\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 3. Model 구성\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. keras.Model 을 상속받았으며, __init__()와 call() 메소드를 가진 모델 클래스\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "7. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
    "\"\"\"\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.max1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.max2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.max1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()\n",
    "\n",
    "# 4. 모델 학습 설정\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sharp-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n",
      "Epoch 0: last batch loss = 4.5210\n",
      "Epoch 1: last batch loss = 4.5039\n",
      "Epoch 2: last batch loss = 4.3028\n",
      "Epoch 3: last batch loss = 3.9483\n",
      "Epoch 4: last batch loss = 3.7302\n",
      "It took 97.25314164161682 seconds\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0367"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientTape 변형\n",
    "\n",
    "# 1. tensorflow, keras, numpy 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 2. 데이터 구성\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 3. model 구성\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()\n",
    "\n",
    "# 4-1. 모델 학습 설정(model.compile)\n",
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# 4-2. 모델 학습 설정(model.fit)\n",
    "import time\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            if step % batch_size == batch_size-1:\n",
    "                x_batch.append(x)\n",
    "                y_batch.append(y)\n",
    "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()\n",
    "\n",
    "# 4-3. 모델 학습 설정(model.predict)\n",
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
