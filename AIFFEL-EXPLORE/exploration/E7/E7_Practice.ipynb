{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sixth-rachel",
   "metadata": {},
   "source": [
    "# E7. Practice : Sentimental_Analysis\n",
    "## 1. 텍스트 데이터의 숫자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "innovative-entertainment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "disabled-evans",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "impressive-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "registered-heating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "successful-concord",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "buried-penetration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "psychological-mainstream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "correct-douglas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tribal-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-hurricane",
   "metadata": {},
   "source": [
    "## 2. 텍스트 데이터의 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "powerful-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.04637351  0.01422805 -0.03968296  0.00294168]\n",
      "  [ 0.02569654 -0.03632613 -0.02517409 -0.00983285]\n",
      "  [-0.01643724 -0.00998569 -0.02208745  0.04046854]\n",
      "  [-0.01916434  0.01146612  0.02446688 -0.0020074 ]\n",
      "  [-0.04888525  0.01780555 -0.00148054  0.02220349]]\n",
      "\n",
      " [[-0.04637351  0.01422805 -0.03968296  0.00294168]\n",
      "  [ 0.02569654 -0.03632613 -0.02517409 -0.00983285]\n",
      "  [-0.04407512  0.01513073  0.04730267  0.02152092]\n",
      "  [-0.00616028 -0.01529126  0.02703598 -0.02628131]\n",
      "  [-0.04888525  0.01780555 -0.00148054  0.02220349]]\n",
      "\n",
      " [[-0.04637351  0.01422805 -0.03968296  0.00294168]\n",
      "  [-0.03936244  0.01775118  0.04613193  0.01756951]\n",
      "  [ 0.02569654 -0.03632613 -0.02517409 -0.00983285]\n",
      "  [-0.01643724 -0.00998569 -0.02208745  0.04046854]\n",
      "  [ 0.0061805   0.01645151  0.00836426  0.03897507]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unlimited-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "still-cleaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fossil-sandwich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-airfare",
   "metadata": {},
   "source": [
    "## 3. IMDb 영화리뷰 감성분석 \n",
    "### 3-1. 데이터셋 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "tutorial-enclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "international-desire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ecological-bicycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '<PAD>'),\n",
       " (1, '<BOS>'),\n",
       " (2, '<UNK>'),\n",
       " (3, '<UNUSED>'),\n",
       " (4, 'the'),\n",
       " (5, 'and'),\n",
       " (6, 'a'),\n",
       " (7, 'of'),\n",
       " (8, 'to'),\n",
       " (9, 'is'),\n",
       " (10, 'br'),\n",
       " (11, 'in'),\n",
       " (12, 'it'),\n",
       " (13, 'i'),\n",
       " (14, 'this'),\n",
       " (15, 'that'),\n",
       " (16, 'was'),\n",
       " (17, 'as'),\n",
       " (18, 'for'),\n",
       " (19, 'with'),\n",
       " (20, 'movie'),\n",
       " (21, 'but'),\n",
       " (22, 'film'),\n",
       " (23, 'on'),\n",
       " (24, 'not'),\n",
       " (25, 'you'),\n",
       " (26, 'are'),\n",
       " (27, 'his'),\n",
       " (28, 'have'),\n",
       " (29, 'he'),\n",
       " (30, 'be'),\n",
       " (31, 'one'),\n",
       " (32, 'all'),\n",
       " (33, 'at'),\n",
       " (34, 'by'),\n",
       " (35, 'an'),\n",
       " (36, 'they'),\n",
       " (37, 'who'),\n",
       " (38, 'so'),\n",
       " (39, 'from'),\n",
       " (40, 'like'),\n",
       " (41, 'her'),\n",
       " (42, 'or'),\n",
       " (43, 'just'),\n",
       " (44, 'about'),\n",
       " (45, \"it's\"),\n",
       " (46, 'out'),\n",
       " (47, 'has'),\n",
       " (48, 'if'),\n",
       " (49, 'some'),\n",
       " (50, 'there'),\n",
       " (51, 'what'),\n",
       " (52, 'good'),\n",
       " (53, 'more'),\n",
       " (54, 'when'),\n",
       " (55, 'very'),\n",
       " (56, 'up'),\n",
       " (57, 'no'),\n",
       " (58, 'time'),\n",
       " (59, 'she'),\n",
       " (60, 'even'),\n",
       " (61, 'my'),\n",
       " (62, 'would'),\n",
       " (63, 'which'),\n",
       " (64, 'only'),\n",
       " (65, 'story'),\n",
       " (66, 'really'),\n",
       " (67, 'see'),\n",
       " (68, 'their'),\n",
       " (69, 'had'),\n",
       " (70, 'can'),\n",
       " (71, 'were'),\n",
       " (72, 'me'),\n",
       " (73, 'well'),\n",
       " (74, 'than'),\n",
       " (75, 'we'),\n",
       " (76, 'much'),\n",
       " (77, 'been'),\n",
       " (78, 'bad'),\n",
       " (79, 'get'),\n",
       " (80, 'will'),\n",
       " (81, 'do'),\n",
       " (82, 'also'),\n",
       " (83, 'into'),\n",
       " (84, 'people'),\n",
       " (85, 'other'),\n",
       " (86, 'first'),\n",
       " (87, 'great'),\n",
       " (88, 'because'),\n",
       " (89, 'how'),\n",
       " (90, 'him'),\n",
       " (91, 'most'),\n",
       " (92, \"don't\"),\n",
       " (93, 'made'),\n",
       " (94, 'its'),\n",
       " (95, 'then'),\n",
       " (96, 'way'),\n",
       " (97, 'make'),\n",
       " (98, 'them'),\n",
       " (99, 'too'),\n",
       " (100, 'could'),\n",
       " (101, 'any'),\n",
       " (102, 'movies'),\n",
       " (103, 'after'),\n",
       " (104, 'think'),\n",
       " (105, 'characters'),\n",
       " (106, 'watch'),\n",
       " (107, 'two'),\n",
       " (108, 'films'),\n",
       " (109, 'character'),\n",
       " (110, 'seen'),\n",
       " (111, 'many'),\n",
       " (112, 'being'),\n",
       " (113, 'life'),\n",
       " (114, 'plot'),\n",
       " (115, 'never'),\n",
       " (116, 'acting'),\n",
       " (117, 'little'),\n",
       " (118, 'best'),\n",
       " (119, 'love'),\n",
       " (120, 'over'),\n",
       " (121, 'where'),\n",
       " (122, 'did'),\n",
       " (123, 'show'),\n",
       " (124, 'know'),\n",
       " (125, 'off'),\n",
       " (126, 'ever'),\n",
       " (127, 'does'),\n",
       " (128, 'better'),\n",
       " (129, 'your'),\n",
       " (130, 'end'),\n",
       " (131, 'still'),\n",
       " (132, 'man'),\n",
       " (133, 'here'),\n",
       " (134, 'these'),\n",
       " (135, 'say'),\n",
       " (136, 'scene'),\n",
       " (137, 'while'),\n",
       " (138, 'why'),\n",
       " (139, 'scenes'),\n",
       " (140, 'go'),\n",
       " (141, 'such'),\n",
       " (142, 'something'),\n",
       " (143, 'through'),\n",
       " (144, 'should'),\n",
       " (145, 'back'),\n",
       " (146, \"i'm\"),\n",
       " (147, 'real'),\n",
       " (148, 'those'),\n",
       " (149, 'watching'),\n",
       " (150, 'now'),\n",
       " (151, 'though'),\n",
       " (152, \"doesn't\"),\n",
       " (153, 'years'),\n",
       " (154, 'old'),\n",
       " (155, 'thing'),\n",
       " (156, 'actors'),\n",
       " (157, 'work'),\n",
       " (158, '10'),\n",
       " (159, 'before'),\n",
       " (160, 'another'),\n",
       " (161, \"didn't\"),\n",
       " (162, 'new'),\n",
       " (163, 'funny'),\n",
       " (164, 'nothing'),\n",
       " (165, 'actually'),\n",
       " (166, 'makes'),\n",
       " (167, 'director'),\n",
       " (168, 'look'),\n",
       " (169, 'find'),\n",
       " (170, 'going'),\n",
       " (171, 'few'),\n",
       " (172, 'same'),\n",
       " (173, 'part'),\n",
       " (174, 'again'),\n",
       " (175, 'every'),\n",
       " (176, 'lot'),\n",
       " (177, 'cast'),\n",
       " (178, 'us'),\n",
       " (179, 'quite'),\n",
       " (180, 'down'),\n",
       " (181, 'want'),\n",
       " (182, 'world'),\n",
       " (183, 'things'),\n",
       " (184, 'pretty'),\n",
       " (185, 'young'),\n",
       " (186, 'seems'),\n",
       " (187, 'around'),\n",
       " (188, 'got'),\n",
       " (189, 'horror'),\n",
       " (190, 'however'),\n",
       " (191, \"can't\"),\n",
       " (192, 'fact'),\n",
       " (193, 'take'),\n",
       " (194, 'big'),\n",
       " (195, 'enough'),\n",
       " (196, 'long'),\n",
       " (197, 'thought'),\n",
       " (198, \"that's\"),\n",
       " (199, 'both'),\n",
       " (200, 'between'),\n",
       " (201, 'series'),\n",
       " (202, 'give'),\n",
       " (203, 'may'),\n",
       " (204, 'original'),\n",
       " (205, 'own'),\n",
       " (206, 'action'),\n",
       " (207, \"i've\"),\n",
       " (208, 'right'),\n",
       " (209, 'without'),\n",
       " (210, 'always'),\n",
       " (211, 'times'),\n",
       " (212, 'comedy'),\n",
       " (213, 'point'),\n",
       " (214, 'gets'),\n",
       " (215, 'must'),\n",
       " (216, 'come'),\n",
       " (217, 'role'),\n",
       " (218, \"isn't\"),\n",
       " (219, 'saw'),\n",
       " (220, 'almost'),\n",
       " (221, 'interesting'),\n",
       " (222, 'least'),\n",
       " (223, 'family'),\n",
       " (224, 'done'),\n",
       " (225, \"there's\"),\n",
       " (226, 'whole'),\n",
       " (227, 'bit'),\n",
       " (228, 'music'),\n",
       " (229, 'script'),\n",
       " (230, 'far'),\n",
       " (231, 'making'),\n",
       " (232, 'guy'),\n",
       " (233, 'anything'),\n",
       " (234, 'minutes'),\n",
       " (235, 'feel'),\n",
       " (236, 'last'),\n",
       " (237, 'since'),\n",
       " (238, 'might'),\n",
       " (239, 'performance'),\n",
       " (240, \"he's\"),\n",
       " (241, '2'),\n",
       " (242, 'probably'),\n",
       " (243, 'kind'),\n",
       " (244, 'am'),\n",
       " (245, 'away'),\n",
       " (246, 'yet'),\n",
       " (247, 'rather'),\n",
       " (248, 'tv'),\n",
       " (249, 'worst'),\n",
       " (250, 'girl'),\n",
       " (251, 'day'),\n",
       " (252, 'sure'),\n",
       " (253, 'fun'),\n",
       " (254, 'hard'),\n",
       " (255, 'woman'),\n",
       " (256, 'played'),\n",
       " (257, 'each'),\n",
       " (258, 'found'),\n",
       " (259, 'anyone'),\n",
       " (260, 'having'),\n",
       " (261, 'although'),\n",
       " (262, 'especially'),\n",
       " (263, 'our'),\n",
       " (264, 'believe'),\n",
       " (265, 'course'),\n",
       " (266, 'comes'),\n",
       " (267, 'looking'),\n",
       " (268, 'screen'),\n",
       " (269, 'trying'),\n",
       " (270, 'set'),\n",
       " (271, 'goes'),\n",
       " (272, 'looks'),\n",
       " (273, 'place'),\n",
       " (274, 'book'),\n",
       " (275, 'different'),\n",
       " (276, 'put'),\n",
       " (277, 'ending'),\n",
       " (278, 'money'),\n",
       " (279, 'maybe'),\n",
       " (280, 'once'),\n",
       " (281, 'sense'),\n",
       " (282, 'reason'),\n",
       " (283, 'true'),\n",
       " (284, 'actor'),\n",
       " (285, 'everything'),\n",
       " (286, \"wasn't\"),\n",
       " (287, 'shows'),\n",
       " (288, 'dvd'),\n",
       " (289, 'three'),\n",
       " (290, 'worth'),\n",
       " (291, 'year'),\n",
       " (292, 'job'),\n",
       " (293, 'main'),\n",
       " (294, 'someone'),\n",
       " (295, 'together'),\n",
       " (296, 'watched'),\n",
       " (297, 'play'),\n",
       " (298, 'american'),\n",
       " (299, 'plays'),\n",
       " (300, '1'),\n",
       " (301, 'said'),\n",
       " (302, 'effects'),\n",
       " (303, 'later'),\n",
       " (304, 'takes'),\n",
       " (305, 'instead'),\n",
       " (306, 'seem'),\n",
       " (307, 'beautiful'),\n",
       " (308, 'john'),\n",
       " (309, 'himself'),\n",
       " (310, 'version'),\n",
       " (311, 'audience'),\n",
       " (312, 'high'),\n",
       " (313, 'house'),\n",
       " (314, 'night'),\n",
       " (315, 'during'),\n",
       " (316, 'everyone'),\n",
       " (317, 'left'),\n",
       " (318, 'special'),\n",
       " (319, 'seeing'),\n",
       " (320, 'half'),\n",
       " (321, 'excellent'),\n",
       " (322, 'wife'),\n",
       " (323, 'star'),\n",
       " (324, 'shot'),\n",
       " (325, 'war'),\n",
       " (326, 'idea'),\n",
       " (327, 'nice'),\n",
       " (328, 'black'),\n",
       " (329, 'less'),\n",
       " (330, 'mind'),\n",
       " (331, 'simply'),\n",
       " (332, 'read'),\n",
       " (333, 'second'),\n",
       " (334, 'else'),\n",
       " (335, \"you're\"),\n",
       " (336, 'father'),\n",
       " (337, 'fan'),\n",
       " (338, 'poor'),\n",
       " (339, 'help'),\n",
       " (340, 'completely'),\n",
       " (341, 'death'),\n",
       " (342, '3'),\n",
       " (343, 'used'),\n",
       " (344, 'home'),\n",
       " (345, 'either'),\n",
       " (346, 'short'),\n",
       " (347, 'line'),\n",
       " (348, 'given'),\n",
       " (349, 'men'),\n",
       " (350, 'top'),\n",
       " (351, 'dead'),\n",
       " (352, 'budget'),\n",
       " (353, 'try'),\n",
       " (354, 'performances'),\n",
       " (355, 'wrong'),\n",
       " (356, 'classic'),\n",
       " (357, 'boring'),\n",
       " (358, 'enjoy'),\n",
       " (359, 'need'),\n",
       " (360, 'rest'),\n",
       " (361, 'use'),\n",
       " (362, 'kids'),\n",
       " (363, 'hollywood'),\n",
       " (364, 'low'),\n",
       " (365, 'production'),\n",
       " (366, 'until'),\n",
       " (367, 'along'),\n",
       " (368, 'full'),\n",
       " (369, 'friends'),\n",
       " (370, 'camera'),\n",
       " (371, 'truly'),\n",
       " (372, 'women'),\n",
       " (373, 'awful'),\n",
       " (374, 'video'),\n",
       " (375, 'next'),\n",
       " (376, 'tell'),\n",
       " (377, 'remember'),\n",
       " (378, 'couple'),\n",
       " (379, 'stupid'),\n",
       " (380, 'start'),\n",
       " (381, 'stars'),\n",
       " (382, 'perhaps'),\n",
       " (383, 'sex'),\n",
       " (384, 'mean'),\n",
       " (385, 'came'),\n",
       " (386, 'recommend'),\n",
       " (387, 'let'),\n",
       " (388, 'moments'),\n",
       " (389, 'wonderful'),\n",
       " (390, 'episode'),\n",
       " (391, 'understand'),\n",
       " (392, 'small'),\n",
       " (393, 'face'),\n",
       " (394, 'terrible'),\n",
       " (395, 'playing'),\n",
       " (396, 'school'),\n",
       " (397, 'getting'),\n",
       " (398, 'written'),\n",
       " (399, 'doing'),\n",
       " (400, 'often'),\n",
       " (401, 'keep'),\n",
       " (402, 'early'),\n",
       " (403, 'name'),\n",
       " (404, 'perfect'),\n",
       " (405, 'style'),\n",
       " (406, 'human'),\n",
       " (407, 'definitely'),\n",
       " (408, 'gives'),\n",
       " (409, 'others'),\n",
       " (410, 'itself'),\n",
       " (411, 'lines'),\n",
       " (412, 'live'),\n",
       " (413, 'become'),\n",
       " (414, 'dialogue'),\n",
       " (415, 'person'),\n",
       " (416, 'lost'),\n",
       " (417, 'finally'),\n",
       " (418, 'piece'),\n",
       " (419, 'head'),\n",
       " (420, 'case'),\n",
       " (421, 'felt'),\n",
       " (422, 'yes'),\n",
       " (423, 'liked'),\n",
       " (424, 'supposed'),\n",
       " (425, 'title'),\n",
       " (426, \"couldn't\"),\n",
       " (427, 'absolutely'),\n",
       " (428, 'white'),\n",
       " (429, 'against'),\n",
       " (430, 'boy'),\n",
       " (431, 'picture'),\n",
       " (432, 'sort'),\n",
       " (433, 'worse'),\n",
       " (434, 'certainly'),\n",
       " (435, 'went'),\n",
       " (436, 'entire'),\n",
       " (437, 'waste'),\n",
       " (438, 'cinema'),\n",
       " (439, 'problem'),\n",
       " (440, 'hope'),\n",
       " (441, 'entertaining'),\n",
       " (442, \"she's\"),\n",
       " (443, 'mr'),\n",
       " (444, 'overall'),\n",
       " (445, 'evil'),\n",
       " (446, 'called'),\n",
       " (447, 'loved'),\n",
       " (448, 'based'),\n",
       " (449, 'oh'),\n",
       " (450, 'several'),\n",
       " (451, 'fans'),\n",
       " (452, 'mother'),\n",
       " (453, 'drama'),\n",
       " (454, 'beginning'),\n",
       " (455, 'killer'),\n",
       " (456, 'lives'),\n",
       " (457, '5'),\n",
       " (458, 'direction'),\n",
       " (459, 'care'),\n",
       " (460, 'already'),\n",
       " (461, 'becomes'),\n",
       " (462, 'laugh'),\n",
       " (463, 'example'),\n",
       " (464, 'friend'),\n",
       " (465, 'dark'),\n",
       " (466, 'despite'),\n",
       " (467, 'under'),\n",
       " (468, 'seemed'),\n",
       " (469, 'throughout'),\n",
       " (470, '4'),\n",
       " (471, 'turn'),\n",
       " (472, 'unfortunately'),\n",
       " (473, 'wanted'),\n",
       " (474, \"i'd\"),\n",
       " (475, '\\x96'),\n",
       " (476, 'children'),\n",
       " (477, 'final'),\n",
       " (478, 'fine'),\n",
       " (479, 'history'),\n",
       " (480, 'amazing'),\n",
       " (481, 'sound'),\n",
       " (482, 'guess'),\n",
       " (483, 'heart'),\n",
       " (484, 'totally'),\n",
       " (485, 'lead'),\n",
       " (486, 'humor'),\n",
       " (487, 'writing'),\n",
       " (488, 'michael'),\n",
       " (489, 'quality'),\n",
       " (490, \"you'll\"),\n",
       " (491, 'close'),\n",
       " (492, 'son'),\n",
       " (493, 'guys'),\n",
       " (494, 'wants'),\n",
       " (495, 'works'),\n",
       " (496, 'behind'),\n",
       " (497, 'tries'),\n",
       " (498, 'art'),\n",
       " (499, 'side'),\n",
       " (500, 'game'),\n",
       " (501, 'past'),\n",
       " (502, 'able'),\n",
       " (503, 'b'),\n",
       " (504, 'days'),\n",
       " (505, 'turns'),\n",
       " (506, 'child'),\n",
       " (507, \"they're\"),\n",
       " (508, 'hand'),\n",
       " (509, 'flick'),\n",
       " (510, 'enjoyed'),\n",
       " (511, 'act'),\n",
       " (512, 'genre'),\n",
       " (513, 'town'),\n",
       " (514, 'favorite'),\n",
       " (515, 'soon'),\n",
       " (516, 'kill'),\n",
       " (517, 'starts'),\n",
       " (518, 'sometimes'),\n",
       " (519, 'car'),\n",
       " (520, 'gave'),\n",
       " (521, 'run'),\n",
       " (522, 'late'),\n",
       " (523, 'eyes'),\n",
       " (524, 'actress'),\n",
       " (525, 'etc'),\n",
       " (526, 'directed'),\n",
       " (527, 'horrible'),\n",
       " (528, \"won't\"),\n",
       " (529, 'viewer'),\n",
       " (530, 'brilliant'),\n",
       " (531, 'parts'),\n",
       " (532, 'self'),\n",
       " (533, 'themselves'),\n",
       " (534, 'hour'),\n",
       " (535, 'expect'),\n",
       " (536, 'thinking'),\n",
       " (537, 'stories'),\n",
       " (538, 'stuff'),\n",
       " (539, 'girls'),\n",
       " (540, 'obviously'),\n",
       " (541, 'blood'),\n",
       " (542, 'decent'),\n",
       " (543, 'city'),\n",
       " (544, 'voice'),\n",
       " (545, 'highly'),\n",
       " (546, 'myself'),\n",
       " (547, 'feeling'),\n",
       " (548, 'fight'),\n",
       " (549, 'except'),\n",
       " (550, 'slow'),\n",
       " (551, 'matter'),\n",
       " (552, 'type'),\n",
       " (553, 'anyway'),\n",
       " (554, 'kid'),\n",
       " (555, 'roles'),\n",
       " (556, 'killed'),\n",
       " (557, 'heard'),\n",
       " (558, 'god'),\n",
       " (559, 'age'),\n",
       " (560, 'says'),\n",
       " (561, 'moment'),\n",
       " (562, 'took'),\n",
       " (563, 'leave'),\n",
       " (564, 'writer'),\n",
       " (565, 'strong'),\n",
       " (566, 'cannot'),\n",
       " (567, 'violence'),\n",
       " (568, 'police'),\n",
       " (569, 'hit'),\n",
       " (570, 'stop'),\n",
       " (571, 'happens'),\n",
       " (572, 'particularly'),\n",
       " (573, 'known'),\n",
       " (574, 'involved'),\n",
       " (575, 'happened'),\n",
       " (576, 'extremely'),\n",
       " (577, 'daughter'),\n",
       " (578, 'obvious'),\n",
       " (579, 'told'),\n",
       " (580, 'chance'),\n",
       " (581, 'living'),\n",
       " (582, 'coming'),\n",
       " (583, 'lack'),\n",
       " (584, 'alone'),\n",
       " (585, 'experience'),\n",
       " (586, \"wouldn't\"),\n",
       " (587, 'including'),\n",
       " (588, 'murder'),\n",
       " (589, 'attempt'),\n",
       " (590, 's'),\n",
       " (591, 'please'),\n",
       " (592, 'james'),\n",
       " (593, 'happen'),\n",
       " (594, 'wonder'),\n",
       " (595, 'crap'),\n",
       " (596, 'ago'),\n",
       " (597, 'brother'),\n",
       " (598, \"film's\"),\n",
       " (599, 'gore'),\n",
       " (600, 'none'),\n",
       " (601, 'complete'),\n",
       " (602, 'interest'),\n",
       " (603, 'score'),\n",
       " (604, 'group'),\n",
       " (605, 'cut'),\n",
       " (606, 'simple'),\n",
       " (607, 'save'),\n",
       " (608, 'ok'),\n",
       " (609, 'hell'),\n",
       " (610, 'looked'),\n",
       " (611, 'career'),\n",
       " (612, 'number'),\n",
       " (613, 'song'),\n",
       " (614, 'possible'),\n",
       " (615, 'seriously'),\n",
       " (616, 'annoying'),\n",
       " (617, 'shown'),\n",
       " (618, 'exactly'),\n",
       " (619, 'sad'),\n",
       " (620, 'running'),\n",
       " (621, 'musical'),\n",
       " (622, 'serious'),\n",
       " (623, 'taken'),\n",
       " (624, 'yourself'),\n",
       " (625, 'whose'),\n",
       " (626, 'released'),\n",
       " (627, 'cinematography'),\n",
       " (628, 'david'),\n",
       " (629, 'scary'),\n",
       " (630, 'ends'),\n",
       " (631, 'english'),\n",
       " (632, 'hero'),\n",
       " (633, 'usually'),\n",
       " (634, 'hours'),\n",
       " (635, 'reality'),\n",
       " (636, 'opening'),\n",
       " (637, \"i'll\"),\n",
       " (638, 'across'),\n",
       " (639, 'today'),\n",
       " (640, 'jokes'),\n",
       " (641, 'light'),\n",
       " (642, 'hilarious'),\n",
       " (643, 'somewhat'),\n",
       " (644, 'usual'),\n",
       " (645, 'started'),\n",
       " (646, 'cool'),\n",
       " (647, 'ridiculous'),\n",
       " (648, 'body'),\n",
       " (649, 'relationship'),\n",
       " (650, 'view'),\n",
       " (651, 'level'),\n",
       " (652, 'opinion'),\n",
       " (653, 'change'),\n",
       " (654, 'happy'),\n",
       " (655, 'middle'),\n",
       " (656, 'taking'),\n",
       " (657, 'wish'),\n",
       " (658, 'husband'),\n",
       " (659, 'finds'),\n",
       " (660, 'saying'),\n",
       " (661, 'order'),\n",
       " (662, 'talking'),\n",
       " (663, 'ones'),\n",
       " (664, 'documentary'),\n",
       " (665, 'shots'),\n",
       " (666, 'huge'),\n",
       " (667, 'novel'),\n",
       " (668, 'female'),\n",
       " (669, 'mostly'),\n",
       " (670, 'robert'),\n",
       " (671, 'power'),\n",
       " (672, 'episodes'),\n",
       " (673, 'room'),\n",
       " (674, 'important'),\n",
       " (675, 'rating'),\n",
       " (676, 'talent'),\n",
       " (677, 'five'),\n",
       " (678, 'major'),\n",
       " (679, 'turned'),\n",
       " (680, 'strange'),\n",
       " (681, 'word'),\n",
       " (682, 'modern'),\n",
       " (683, 'call'),\n",
       " (684, 'apparently'),\n",
       " (685, 'disappointed'),\n",
       " (686, 'single'),\n",
       " (687, 'events'),\n",
       " (688, 'due'),\n",
       " (689, 'four'),\n",
       " (690, 'songs'),\n",
       " (691, 'basically'),\n",
       " (692, 'attention'),\n",
       " (693, '7'),\n",
       " (694, 'knows'),\n",
       " (695, 'clearly'),\n",
       " (696, 'supporting'),\n",
       " (697, 'knew'),\n",
       " (698, 'british'),\n",
       " (699, 'television'),\n",
       " (700, 'comic'),\n",
       " (701, 'non'),\n",
       " (702, 'fast'),\n",
       " (703, 'earth'),\n",
       " (704, 'country'),\n",
       " (705, 'future'),\n",
       " (706, 'cheap'),\n",
       " (707, 'class'),\n",
       " (708, 'thriller'),\n",
       " (709, '8'),\n",
       " (710, 'silly'),\n",
       " (711, 'king'),\n",
       " (712, 'problems'),\n",
       " (713, \"aren't\"),\n",
       " (714, 'easily'),\n",
       " (715, 'words'),\n",
       " (716, 'tells'),\n",
       " (717, 'miss'),\n",
       " (718, 'jack'),\n",
       " (719, 'local'),\n",
       " (720, 'sequence'),\n",
       " (721, 'bring'),\n",
       " (722, 'entertainment'),\n",
       " (723, 'paul'),\n",
       " (724, 'beyond'),\n",
       " (725, 'upon'),\n",
       " (726, 'whether'),\n",
       " (727, 'predictable'),\n",
       " (728, 'moving'),\n",
       " (729, 'similar'),\n",
       " (730, 'straight'),\n",
       " (731, 'romantic'),\n",
       " (732, 'sets'),\n",
       " (733, 'review'),\n",
       " (734, 'falls'),\n",
       " (735, 'oscar'),\n",
       " (736, 'mystery'),\n",
       " (737, 'enjoyable'),\n",
       " (738, 'needs'),\n",
       " (739, 'appears'),\n",
       " (740, 'talk'),\n",
       " (741, 'rock'),\n",
       " (742, 'george'),\n",
       " (743, 'giving'),\n",
       " (744, 'eye'),\n",
       " (745, 'richard'),\n",
       " (746, 'within'),\n",
       " (747, 'ten'),\n",
       " (748, 'animation'),\n",
       " (749, 'message'),\n",
       " (750, 'theater'),\n",
       " (751, 'near'),\n",
       " (752, 'above'),\n",
       " (753, 'dull'),\n",
       " (754, 'nearly'),\n",
       " (755, 'sequel'),\n",
       " (756, 'theme'),\n",
       " (757, 'points'),\n",
       " (758, \"'\"),\n",
       " (759, 'stand'),\n",
       " (760, 'mention'),\n",
       " (761, 'lady'),\n",
       " (762, 'bunch'),\n",
       " (763, 'add'),\n",
       " (764, 'feels'),\n",
       " (765, 'herself'),\n",
       " (766, 'release'),\n",
       " (767, 'red'),\n",
       " (768, 'team'),\n",
       " (769, 'storyline'),\n",
       " (770, 'surprised'),\n",
       " (771, 'ways'),\n",
       " (772, 'using'),\n",
       " (773, 'named'),\n",
       " (774, \"haven't\"),\n",
       " (775, 'lots'),\n",
       " (776, 'easy'),\n",
       " (777, 'fantastic'),\n",
       " (778, 'begins'),\n",
       " (779, 'actual'),\n",
       " (780, 'working'),\n",
       " (781, 'effort'),\n",
       " (782, 'york'),\n",
       " (783, 'die'),\n",
       " (784, 'hate'),\n",
       " (785, 'french'),\n",
       " (786, 'minute'),\n",
       " (787, 'tale'),\n",
       " (788, 'clear'),\n",
       " (789, 'stay'),\n",
       " (790, '9'),\n",
       " (791, 'elements'),\n",
       " (792, 'feature'),\n",
       " (793, 'among'),\n",
       " (794, 'follow'),\n",
       " (795, 'comments'),\n",
       " (796, 're'),\n",
       " (797, 'viewers'),\n",
       " (798, 'avoid'),\n",
       " (799, 'sister'),\n",
       " (800, 'showing'),\n",
       " (801, 'typical'),\n",
       " (802, 'editing'),\n",
       " (803, \"what's\"),\n",
       " (804, 'famous'),\n",
       " (805, 'tried'),\n",
       " (806, 'sorry'),\n",
       " (807, 'dialog'),\n",
       " (808, 'check'),\n",
       " (809, 'fall'),\n",
       " (810, 'period'),\n",
       " (811, 'season'),\n",
       " (812, 'form'),\n",
       " (813, 'certain'),\n",
       " (814, 'filmed'),\n",
       " (815, 'weak'),\n",
       " (816, 'soundtrack'),\n",
       " (817, 'means'),\n",
       " (818, 'buy'),\n",
       " (819, 'material'),\n",
       " (820, 'somehow'),\n",
       " (821, 'realistic'),\n",
       " (822, 'figure'),\n",
       " (823, 'crime'),\n",
       " (824, 'doubt'),\n",
       " (825, 'gone'),\n",
       " (826, 'peter'),\n",
       " (827, 'tom'),\n",
       " (828, 'kept'),\n",
       " (829, 'viewing'),\n",
       " (830, 't'),\n",
       " (831, 'general'),\n",
       " (832, 'leads'),\n",
       " (833, 'greatest'),\n",
       " (834, 'space'),\n",
       " (835, 'lame'),\n",
       " (836, 'suspense'),\n",
       " (837, 'dance'),\n",
       " (838, 'imagine'),\n",
       " (839, 'brought'),\n",
       " (840, 'third'),\n",
       " (841, 'atmosphere'),\n",
       " (842, 'hear'),\n",
       " (843, 'particular'),\n",
       " (844, 'sequences'),\n",
       " (845, 'whatever'),\n",
       " (846, 'parents'),\n",
       " (847, 'move'),\n",
       " (848, 'lee'),\n",
       " (849, 'indeed'),\n",
       " (850, 'learn'),\n",
       " (851, 'rent'),\n",
       " (852, 'de'),\n",
       " (853, 'eventually'),\n",
       " (854, 'note'),\n",
       " (855, 'deal'),\n",
       " (856, 'average'),\n",
       " (857, 'reviews'),\n",
       " (858, 'wait'),\n",
       " (859, 'forget'),\n",
       " (860, 'japanese'),\n",
       " (861, 'sexual'),\n",
       " (862, 'poorly'),\n",
       " (863, 'premise'),\n",
       " (864, 'okay'),\n",
       " (865, 'zombie'),\n",
       " (866, 'surprise'),\n",
       " (867, 'believable'),\n",
       " (868, 'stage'),\n",
       " (869, 'possibly'),\n",
       " (870, 'sit'),\n",
       " (871, \"who's\"),\n",
       " (872, 'decided'),\n",
       " (873, 'expected'),\n",
       " (874, \"you've\"),\n",
       " (875, 'subject'),\n",
       " (876, 'nature'),\n",
       " (877, 'became'),\n",
       " (878, 'difficult'),\n",
       " (879, 'free'),\n",
       " (880, 'killing'),\n",
       " (881, 'screenplay'),\n",
       " (882, 'truth'),\n",
       " (883, 'romance'),\n",
       " (884, 'dr'),\n",
       " (885, 'nor'),\n",
       " (886, 'reading'),\n",
       " (887, 'needed'),\n",
       " (888, 'question'),\n",
       " (889, 'leaves'),\n",
       " (890, 'street'),\n",
       " (891, '20'),\n",
       " (892, 'meets'),\n",
       " (893, 'hot'),\n",
       " (894, 'unless'),\n",
       " (895, 'begin'),\n",
       " (896, 'baby'),\n",
       " (897, 'superb'),\n",
       " (898, 'credits'),\n",
       " (899, 'imdb'),\n",
       " (900, 'otherwise'),\n",
       " (901, 'write'),\n",
       " (902, 'shame'),\n",
       " (903, \"let's\"),\n",
       " (904, 'situation'),\n",
       " (905, 'dramatic'),\n",
       " (906, 'memorable'),\n",
       " (907, 'directors'),\n",
       " (908, 'earlier'),\n",
       " (909, 'meet'),\n",
       " (910, 'disney'),\n",
       " (911, 'open'),\n",
       " (912, 'dog'),\n",
       " (913, 'badly'),\n",
       " (914, 'joe'),\n",
       " (915, 'male'),\n",
       " (916, 'weird'),\n",
       " (917, 'acted'),\n",
       " (918, 'forced'),\n",
       " (919, 'laughs'),\n",
       " (920, 'sci'),\n",
       " (921, 'emotional'),\n",
       " (922, 'older'),\n",
       " (923, 'realize'),\n",
       " (924, 'fi'),\n",
       " (925, 'dream'),\n",
       " (926, 'society'),\n",
       " (927, 'writers'),\n",
       " (928, 'interested'),\n",
       " (929, 'footage'),\n",
       " (930, 'forward'),\n",
       " (931, 'comment'),\n",
       " (932, 'crazy'),\n",
       " (933, 'deep'),\n",
       " (934, 'sounds'),\n",
       " (935, 'plus'),\n",
       " (936, 'beauty'),\n",
       " (937, 'whom'),\n",
       " (938, 'america'),\n",
       " (939, 'fantasy'),\n",
       " (940, 'directing'),\n",
       " (941, 'keeps'),\n",
       " (942, 'ask'),\n",
       " (943, 'development'),\n",
       " (944, 'features'),\n",
       " (945, 'air'),\n",
       " (946, 'quickly'),\n",
       " (947, 'mess'),\n",
       " (948, 'creepy'),\n",
       " (949, 'towards'),\n",
       " (950, 'perfectly'),\n",
       " (951, 'mark'),\n",
       " (952, 'worked'),\n",
       " (953, 'box'),\n",
       " (954, 'cheesy'),\n",
       " (955, 'unique'),\n",
       " (956, 'setting'),\n",
       " (957, 'hands'),\n",
       " (958, 'plenty'),\n",
       " (959, 'result'),\n",
       " (960, 'previous'),\n",
       " (961, 'brings'),\n",
       " (962, 'effect'),\n",
       " (963, 'e'),\n",
       " (964, 'total'),\n",
       " (965, 'personal'),\n",
       " (966, 'incredibly'),\n",
       " (967, 'rate'),\n",
       " (968, 'fire'),\n",
       " (969, 'monster'),\n",
       " (970, 'business'),\n",
       " (971, 'leading'),\n",
       " (972, 'apart'),\n",
       " (973, 'casting'),\n",
       " (974, 'admit'),\n",
       " (975, 'joke'),\n",
       " (976, 'powerful'),\n",
       " (977, 'appear'),\n",
       " (978, 'background'),\n",
       " (979, 'telling'),\n",
       " (980, 'girlfriend'),\n",
       " (981, 'meant'),\n",
       " (982, 'christmas'),\n",
       " (983, 'hardly'),\n",
       " (984, 'present'),\n",
       " (985, 'battle'),\n",
       " (986, 'potential'),\n",
       " (987, 'create'),\n",
       " (988, 'bill'),\n",
       " (989, 'break'),\n",
       " (990, 'pay'),\n",
       " (991, 'masterpiece'),\n",
       " (992, 'gay'),\n",
       " (993, 'political'),\n",
       " (994, 'return'),\n",
       " (995, 'dumb'),\n",
       " (996, 'fails'),\n",
       " (997, 'fighting'),\n",
       " (998, 'various'),\n",
       " (999, 'era'),\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(index_to_word.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mental-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "impressed-oliver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34704: 'fawn',\n",
       " 52009: 'tsukino',\n",
       " 52010: 'nunnery',\n",
       " 16819: 'sonja',\n",
       " 63954: 'vani',\n",
       " 1411: 'woods',\n",
       " 16118: 'spiders',\n",
       " 2348: 'hanging',\n",
       " 2292: 'woody',\n",
       " 52011: 'trawling',\n",
       " 52012: \"hold's\",\n",
       " 11310: 'comically',\n",
       " 40833: 'localized',\n",
       " 30571: 'disobeying',\n",
       " 52013: \"'royale\",\n",
       " 40834: \"harpo's\",\n",
       " 52014: 'canet',\n",
       " 19316: 'aileen',\n",
       " 52015: 'acurately',\n",
       " 52016: \"diplomat's\",\n",
       " 25245: 'rickman',\n",
       " 6749: 'arranged',\n",
       " 52017: 'rumbustious',\n",
       " 52018: 'familiarness',\n",
       " 52019: \"spider'\",\n",
       " 68807: 'hahahah',\n",
       " 52020: \"wood'\",\n",
       " 40836: 'transvestism',\n",
       " 34705: \"hangin'\",\n",
       " 2341: 'bringing',\n",
       " 40837: 'seamier',\n",
       " 34706: 'wooded',\n",
       " 52021: 'bravora',\n",
       " 16820: 'grueling',\n",
       " 1639: 'wooden',\n",
       " 16821: 'wednesday',\n",
       " 52022: \"'prix\",\n",
       " 34707: 'altagracia',\n",
       " 52023: 'circuitry',\n",
       " 11588: 'crotch',\n",
       " 57769: 'busybody',\n",
       " 52024: \"tart'n'tangy\",\n",
       " 14132: 'burgade',\n",
       " 52026: 'thrace',\n",
       " 11041: \"tom's\",\n",
       " 52028: 'snuggles',\n",
       " 29117: 'francesco',\n",
       " 52030: 'complainers',\n",
       " 52128: 'templarios',\n",
       " 40838: '272',\n",
       " 52031: '273',\n",
       " 52133: 'zaniacs',\n",
       " 34709: '275',\n",
       " 27634: 'consenting',\n",
       " 40839: 'snuggled',\n",
       " 15495: 'inanimate',\n",
       " 52033: 'uality',\n",
       " 11929: 'bronte',\n",
       " 4013: 'errors',\n",
       " 3233: 'dialogs',\n",
       " 52034: \"yomada's\",\n",
       " 34710: \"madman's\",\n",
       " 30588: 'dialoge',\n",
       " 52036: 'usenet',\n",
       " 40840: 'videodrome',\n",
       " 26341: \"kid'\",\n",
       " 52037: 'pawed',\n",
       " 30572: \"'girlfriend'\",\n",
       " 52038: \"'pleasure\",\n",
       " 52039: \"'reloaded'\",\n",
       " 40842: \"kazakos'\",\n",
       " 52040: 'rocque',\n",
       " 52041: 'mailings',\n",
       " 11930: 'brainwashed',\n",
       " 16822: 'mcanally',\n",
       " 52042: \"tom''\",\n",
       " 25246: 'kurupt',\n",
       " 21908: 'affiliated',\n",
       " 52043: 'babaganoosh',\n",
       " 40843: \"noe's\",\n",
       " 40844: 'quart',\n",
       " 362: 'kids',\n",
       " 5037: 'uplifting',\n",
       " 7096: 'controversy',\n",
       " 21909: 'kida',\n",
       " 23382: 'kidd',\n",
       " 52044: \"error'\",\n",
       " 52045: 'neurologist',\n",
       " 18513: 'spotty',\n",
       " 30573: 'cobblers',\n",
       " 9881: 'projection',\n",
       " 40845: 'fastforwarding',\n",
       " 52046: 'sters',\n",
       " 52047: \"eggar's\",\n",
       " 52048: 'etherything',\n",
       " 40846: 'gateshead',\n",
       " 34711: 'airball',\n",
       " 25247: 'unsinkable',\n",
       " 7183: 'stern',\n",
       " 52049: \"cervi's\",\n",
       " 40847: 'dnd',\n",
       " 11589: 'dna',\n",
       " 20601: 'insecurity',\n",
       " 52050: \"'reboot'\",\n",
       " 11040: 'trelkovsky',\n",
       " 52051: 'jaekel',\n",
       " 52052: 'sidebars',\n",
       " 52053: \"sforza's\",\n",
       " 17636: 'distortions',\n",
       " 52054: 'mutinies',\n",
       " 30605: 'sermons',\n",
       " 40849: '7ft',\n",
       " 52055: 'boobage',\n",
       " 52056: \"o'bannon's\",\n",
       " 23383: 'populations',\n",
       " 52057: 'chulak',\n",
       " 27636: 'mesmerize',\n",
       " 52058: 'quinnell',\n",
       " 10310: 'yahoo',\n",
       " 52060: 'meteorologist',\n",
       " 42580: 'beswick',\n",
       " 15496: 'boorman',\n",
       " 40850: 'voicework',\n",
       " 52061: \"ster'\",\n",
       " 22925: 'blustering',\n",
       " 52062: 'hj',\n",
       " 27637: 'intake',\n",
       " 5624: 'morally',\n",
       " 40852: 'jumbling',\n",
       " 52063: 'bowersock',\n",
       " 52064: \"'porky's'\",\n",
       " 16824: 'gershon',\n",
       " 40853: 'ludicrosity',\n",
       " 52065: 'coprophilia',\n",
       " 40854: 'expressively',\n",
       " 19503: \"india's\",\n",
       " 34713: \"post's\",\n",
       " 52066: 'wana',\n",
       " 5286: 'wang',\n",
       " 30574: 'wand',\n",
       " 25248: 'wane',\n",
       " 52324: 'edgeways',\n",
       " 34714: 'titanium',\n",
       " 40855: 'pinta',\n",
       " 181: 'want',\n",
       " 30575: 'pinto',\n",
       " 52068: 'whoopdedoodles',\n",
       " 21911: 'tchaikovsky',\n",
       " 2106: 'travel',\n",
       " 52069: \"'victory'\",\n",
       " 11931: 'copious',\n",
       " 22436: 'gouge',\n",
       " 52070: \"chapters'\",\n",
       " 6705: 'barbra',\n",
       " 30576: 'uselessness',\n",
       " 52071: \"wan'\",\n",
       " 27638: 'assimilated',\n",
       " 16119: 'petiot',\n",
       " 52072: 'most\\x85and',\n",
       " 3933: 'dinosaurs',\n",
       " 355: 'wrong',\n",
       " 52073: 'seda',\n",
       " 52074: 'stollen',\n",
       " 34715: 'sentencing',\n",
       " 40856: 'ouroboros',\n",
       " 40857: 'assimilates',\n",
       " 40858: 'colorfully',\n",
       " 27639: 'glenne',\n",
       " 52075: 'dongen',\n",
       " 4763: 'subplots',\n",
       " 52076: 'kiloton',\n",
       " 23384: 'chandon',\n",
       " 34716: \"effect'\",\n",
       " 27640: 'snugly',\n",
       " 40859: 'kuei',\n",
       " 9095: 'welcomed',\n",
       " 30074: 'dishonor',\n",
       " 52078: 'concurrence',\n",
       " 23385: 'stoicism',\n",
       " 14899: \"guys'\",\n",
       " 52080: \"beroemd'\",\n",
       " 6706: 'butcher',\n",
       " 40860: \"melfi's\",\n",
       " 30626: 'aargh',\n",
       " 20602: 'playhouse',\n",
       " 11311: 'wickedly',\n",
       " 1183: 'fit',\n",
       " 52081: 'labratory',\n",
       " 40862: 'lifeline',\n",
       " 1930: 'screaming',\n",
       " 4290: 'fix',\n",
       " 52082: 'cineliterate',\n",
       " 52083: 'fic',\n",
       " 52084: 'fia',\n",
       " 34717: 'fig',\n",
       " 52085: 'fmvs',\n",
       " 52086: 'fie',\n",
       " 52087: 'reentered',\n",
       " 30577: 'fin',\n",
       " 52088: 'doctresses',\n",
       " 52089: 'fil',\n",
       " 12609: 'zucker',\n",
       " 31934: 'ached',\n",
       " 52091: 'counsil',\n",
       " 52092: 'paterfamilias',\n",
       " 13888: 'songwriter',\n",
       " 34718: 'shivam',\n",
       " 9657: 'hurting',\n",
       " 302: 'effects',\n",
       " 52093: 'slauther',\n",
       " 52094: \"'flame'\",\n",
       " 52095: 'sommerset',\n",
       " 52096: 'interwhined',\n",
       " 27641: 'whacking',\n",
       " 52097: 'bartok',\n",
       " 8778: 'barton',\n",
       " 21912: 'frewer',\n",
       " 52098: \"fi'\",\n",
       " 6195: 'ingrid',\n",
       " 30578: 'stribor',\n",
       " 52099: 'approporiately',\n",
       " 52100: 'wobblyhand',\n",
       " 52101: 'tantalisingly',\n",
       " 52102: 'ankylosaurus',\n",
       " 17637: 'parasites',\n",
       " 52103: 'childen',\n",
       " 52104: \"jenkins'\",\n",
       " 52105: 'metafiction',\n",
       " 17638: 'golem',\n",
       " 40863: 'indiscretion',\n",
       " 23386: \"reeves'\",\n",
       " 57784: \"inamorata's\",\n",
       " 52107: 'brittannica',\n",
       " 7919: 'adapt',\n",
       " 30579: \"russo's\",\n",
       " 48249: 'guitarists',\n",
       " 10556: 'abbott',\n",
       " 40864: 'abbots',\n",
       " 17652: 'lanisha',\n",
       " 40866: 'magickal',\n",
       " 52108: 'mattter',\n",
       " 52109: \"'willy\",\n",
       " 34719: 'pumpkins',\n",
       " 52110: 'stuntpeople',\n",
       " 30580: 'estimate',\n",
       " 40867: 'ugghhh',\n",
       " 11312: 'gameplay',\n",
       " 52111: \"wern't\",\n",
       " 40868: \"n'sync\",\n",
       " 16120: 'sickeningly',\n",
       " 40869: 'chiara',\n",
       " 4014: 'disturbed',\n",
       " 40870: 'portmanteau',\n",
       " 52112: 'ineffectively',\n",
       " 82146: \"duchonvey's\",\n",
       " 37522: \"nasty'\",\n",
       " 1288: 'purpose',\n",
       " 52115: 'lazers',\n",
       " 28108: 'lightened',\n",
       " 52116: 'kaliganj',\n",
       " 52117: 'popularism',\n",
       " 18514: \"damme's\",\n",
       " 30581: 'stylistics',\n",
       " 52118: 'mindgaming',\n",
       " 46452: 'spoilerish',\n",
       " 52120: \"'corny'\",\n",
       " 34721: 'boerner',\n",
       " 6795: 'olds',\n",
       " 52121: 'bakelite',\n",
       " 27642: 'renovated',\n",
       " 27643: 'forrester',\n",
       " 52122: \"lumiere's\",\n",
       " 52027: 'gaskets',\n",
       " 887: 'needed',\n",
       " 34722: 'smight',\n",
       " 1300: 'master',\n",
       " 25908: \"edie's\",\n",
       " 40871: 'seeber',\n",
       " 52123: 'hiya',\n",
       " 52124: 'fuzziness',\n",
       " 14900: 'genesis',\n",
       " 12610: 'rewards',\n",
       " 30582: 'enthrall',\n",
       " 40872: \"'about\",\n",
       " 52125: \"recollection's\",\n",
       " 11042: 'mutilated',\n",
       " 52126: 'fatherlands',\n",
       " 52127: \"fischer's\",\n",
       " 5402: 'positively',\n",
       " 34708: '270',\n",
       " 34723: 'ahmed',\n",
       " 9839: 'zatoichi',\n",
       " 13889: 'bannister',\n",
       " 52130: 'anniversaries',\n",
       " 30583: \"helm's\",\n",
       " 52131: \"'work'\",\n",
       " 34724: 'exclaimed',\n",
       " 52132: \"'unfunny'\",\n",
       " 52032: '274',\n",
       " 547: 'feeling',\n",
       " 52134: \"wanda's\",\n",
       " 33269: 'dolan',\n",
       " 52136: '278',\n",
       " 52137: 'peacoat',\n",
       " 40873: 'brawny',\n",
       " 40874: 'mishra',\n",
       " 40875: 'worlders',\n",
       " 52138: 'protags',\n",
       " 52139: 'skullcap',\n",
       " 57599: 'dastagir',\n",
       " 5625: 'affairs',\n",
       " 7802: 'wholesome',\n",
       " 52140: 'hymen',\n",
       " 25249: 'paramedics',\n",
       " 52141: 'unpersons',\n",
       " 52142: 'heavyarms',\n",
       " 52143: 'affaire',\n",
       " 52144: 'coulisses',\n",
       " 40876: 'hymer',\n",
       " 52145: 'kremlin',\n",
       " 30584: 'shipments',\n",
       " 52146: 'pixilated',\n",
       " 30585: \"'00s\",\n",
       " 18515: 'diminishing',\n",
       " 1360: 'cinematic',\n",
       " 14901: 'resonates',\n",
       " 40877: 'simplify',\n",
       " 40878: \"nature'\",\n",
       " 40879: 'temptresses',\n",
       " 16825: 'reverence',\n",
       " 19505: 'resonated',\n",
       " 34725: 'dailey',\n",
       " 52147: '2\\x85',\n",
       " 27644: 'treize',\n",
       " 52148: 'majo',\n",
       " 21913: 'kiya',\n",
       " 52149: 'woolnough',\n",
       " 39800: 'thanatos',\n",
       " 35734: 'sandoval',\n",
       " 40882: 'dorama',\n",
       " 52150: \"o'shaughnessy\",\n",
       " 4991: 'tech',\n",
       " 32021: 'fugitives',\n",
       " 30586: 'teck',\n",
       " 76128: \"'e'\",\n",
       " 40884: 'doesn’t',\n",
       " 52152: 'purged',\n",
       " 660: 'saying',\n",
       " 41098: \"martians'\",\n",
       " 23421: 'norliss',\n",
       " 27645: 'dickey',\n",
       " 52155: 'dicker',\n",
       " 52156: \"'sependipity\",\n",
       " 8425: 'padded',\n",
       " 57795: 'ordell',\n",
       " 40885: \"sturges'\",\n",
       " 52157: 'independentcritics',\n",
       " 5748: 'tempted',\n",
       " 34727: \"atkinson's\",\n",
       " 25250: 'hounded',\n",
       " 52158: 'apace',\n",
       " 15497: 'clicked',\n",
       " 30587: \"'humor'\",\n",
       " 17180: \"martino's\",\n",
       " 52159: \"'supporting\",\n",
       " 52035: 'warmongering',\n",
       " 34728: \"zemeckis's\",\n",
       " 21914: 'lube',\n",
       " 52160: 'shocky',\n",
       " 7479: 'plate',\n",
       " 40886: 'plata',\n",
       " 40887: 'sturgess',\n",
       " 40888: \"nerds'\",\n",
       " 20603: 'plato',\n",
       " 34729: 'plath',\n",
       " 40889: 'platt',\n",
       " 52162: 'mcnab',\n",
       " 27646: 'clumsiness',\n",
       " 3902: 'altogether',\n",
       " 42587: 'massacring',\n",
       " 52163: 'bicenntinial',\n",
       " 40890: 'skaal',\n",
       " 14363: 'droning',\n",
       " 8779: 'lds',\n",
       " 21915: 'jaguar',\n",
       " 34730: \"cale's\",\n",
       " 1780: 'nicely',\n",
       " 4591: 'mummy',\n",
       " 18516: \"lot's\",\n",
       " 10089: 'patch',\n",
       " 50205: 'kerkhof',\n",
       " 52164: \"leader's\",\n",
       " 27647: \"'movie\",\n",
       " 52165: 'uncomfirmed',\n",
       " 40891: 'heirloom',\n",
       " 47363: 'wrangle',\n",
       " 52166: 'emotion\\x85',\n",
       " 52167: \"'stargate'\",\n",
       " 40892: 'pinoy',\n",
       " 40893: 'conchatta',\n",
       " 41131: 'broeke',\n",
       " 40894: 'advisedly',\n",
       " 17639: \"barker's\",\n",
       " 52169: 'descours',\n",
       " 775: 'lots',\n",
       " 9262: 'lotr',\n",
       " 9882: 'irs',\n",
       " 52170: 'lott',\n",
       " 40895: 'xvi',\n",
       " 34731: 'irk',\n",
       " 52171: 'irl',\n",
       " 6890: 'ira',\n",
       " 21916: 'belzer',\n",
       " 52172: 'irc',\n",
       " 27648: 'ire',\n",
       " 40896: 'requisites',\n",
       " 7696: 'discipline',\n",
       " 52964: 'lyoko',\n",
       " 11313: 'extend',\n",
       " 876: 'nature',\n",
       " 52173: \"'dickie'\",\n",
       " 40897: 'optimist',\n",
       " 30589: 'lapping',\n",
       " 3903: 'superficial',\n",
       " 52174: 'vestment',\n",
       " 2826: 'extent',\n",
       " 52175: 'tendons',\n",
       " 52176: \"heller's\",\n",
       " 52177: 'quagmires',\n",
       " 52178: 'miyako',\n",
       " 20604: 'moocow',\n",
       " 52179: \"coles'\",\n",
       " 40898: 'lookit',\n",
       " 52180: 'ravenously',\n",
       " 40899: 'levitating',\n",
       " 52181: 'perfunctorily',\n",
       " 30590: 'lookin',\n",
       " 40901: \"lot'\",\n",
       " 52182: 'lookie',\n",
       " 34873: 'fearlessly',\n",
       " 52184: 'libyan',\n",
       " 40902: 'fondles',\n",
       " 35717: 'gopher',\n",
       " 40904: 'wearying',\n",
       " 52185: \"nz's\",\n",
       " 27649: 'minuses',\n",
       " 52186: 'puposelessly',\n",
       " 52187: 'shandling',\n",
       " 31271: 'decapitates',\n",
       " 11932: 'humming',\n",
       " 40905: \"'nother\",\n",
       " 21917: 'smackdown',\n",
       " 30591: 'underdone',\n",
       " 40906: 'frf',\n",
       " 52188: 'triviality',\n",
       " 25251: 'fro',\n",
       " 8780: 'bothers',\n",
       " 52189: \"'kensington\",\n",
       " 76: 'much',\n",
       " 34733: 'muco',\n",
       " 22618: 'wiseguy',\n",
       " 27651: \"richie's\",\n",
       " 40907: 'tonino',\n",
       " 52190: 'unleavened',\n",
       " 11590: 'fry',\n",
       " 40908: \"'tv'\",\n",
       " 40909: 'toning',\n",
       " 14364: 'obese',\n",
       " 30592: 'sensationalized',\n",
       " 40910: 'spiv',\n",
       " 6262: 'spit',\n",
       " 7367: 'arkin',\n",
       " 21918: 'charleton',\n",
       " 16826: 'jeon',\n",
       " 21919: 'boardroom',\n",
       " 4992: 'doubts',\n",
       " 3087: 'spin',\n",
       " 53086: 'hepo',\n",
       " 27652: 'wildcat',\n",
       " 10587: 'venoms',\n",
       " 52194: 'misconstrues',\n",
       " 18517: 'mesmerising',\n",
       " 40911: 'misconstrued',\n",
       " 52195: 'rescinds',\n",
       " 52196: 'prostrate',\n",
       " 40912: 'majid',\n",
       " 16482: 'climbed',\n",
       " 34734: 'canoeing',\n",
       " 52198: 'majin',\n",
       " 57807: 'animie',\n",
       " 40913: 'sylke',\n",
       " 14902: 'conditioned',\n",
       " 40914: 'waddell',\n",
       " 52199: '3\\x85',\n",
       " 41191: 'hyperdrive',\n",
       " 34735: 'conditioner',\n",
       " 53156: 'bricklayer',\n",
       " 2579: 'hong',\n",
       " 52201: 'memoriam',\n",
       " 30595: 'inventively',\n",
       " 25252: \"levant's\",\n",
       " 20641: 'portobello',\n",
       " 52203: 'remand',\n",
       " 19507: 'mummified',\n",
       " 27653: 'honk',\n",
       " 19508: 'spews',\n",
       " 40915: 'visitations',\n",
       " 52204: 'mummifies',\n",
       " 25253: 'cavanaugh',\n",
       " 23388: 'zeon',\n",
       " 40916: \"jungle's\",\n",
       " 34736: 'viertel',\n",
       " 27654: 'frenchmen',\n",
       " 52205: 'torpedoes',\n",
       " 52206: 'schlessinger',\n",
       " 34737: 'torpedoed',\n",
       " 69879: 'blister',\n",
       " 52207: 'cinefest',\n",
       " 34738: 'furlough',\n",
       " 52208: 'mainsequence',\n",
       " 40917: 'mentors',\n",
       " 9097: 'academic',\n",
       " 20605: 'stillness',\n",
       " 40918: 'academia',\n",
       " 52209: 'lonelier',\n",
       " 52210: 'nibby',\n",
       " 52211: \"losers'\",\n",
       " 40919: 'cineastes',\n",
       " 4452: 'corporate',\n",
       " 40920: 'massaging',\n",
       " 30596: 'bellow',\n",
       " 19509: 'absurdities',\n",
       " 53244: 'expetations',\n",
       " 40921: 'nyfiken',\n",
       " 75641: 'mehras',\n",
       " 52212: 'lasse',\n",
       " 52213: 'visability',\n",
       " 33949: 'militarily',\n",
       " 52214: \"elder'\",\n",
       " 19026: 'gainsbourg',\n",
       " 20606: 'hah',\n",
       " 13423: 'hai',\n",
       " 34739: 'haj',\n",
       " 25254: 'hak',\n",
       " 4314: 'hal',\n",
       " 4895: 'ham',\n",
       " 53262: 'duffer',\n",
       " 52216: 'haa',\n",
       " 69: 'had',\n",
       " 11933: 'advancement',\n",
       " 16828: 'hag',\n",
       " 25255: \"hand'\",\n",
       " 13424: 'hay',\n",
       " 20607: 'mcnamara',\n",
       " 52217: \"mozart's\",\n",
       " 30734: 'duffel',\n",
       " 30597: 'haq',\n",
       " 13890: 'har',\n",
       " 47: 'has',\n",
       " 2404: 'hat',\n",
       " 40922: 'hav',\n",
       " 30598: 'haw',\n",
       " 52218: 'figtings',\n",
       " 15498: 'elders',\n",
       " 52219: 'underpanted',\n",
       " 52220: 'pninson',\n",
       " 27655: 'unequivocally',\n",
       " 23676: \"barbara's\",\n",
       " 52222: \"bello'\",\n",
       " 13000: 'indicative',\n",
       " 40923: 'yawnfest',\n",
       " 52223: 'hexploitation',\n",
       " 52224: \"loder's\",\n",
       " 27656: 'sleuthing',\n",
       " 32625: \"justin's\",\n",
       " 52225: \"'ball\",\n",
       " 52226: \"'summer\",\n",
       " 34938: \"'demons'\",\n",
       " 52228: \"mormon's\",\n",
       " 34740: \"laughton's\",\n",
       " 52229: 'debell',\n",
       " 39727: 'shipyard',\n",
       " 30600: 'unabashedly',\n",
       " 40404: 'disks',\n",
       " 2293: 'crowd',\n",
       " 10090: 'crowe',\n",
       " 56437: \"vancouver's\",\n",
       " 34741: 'mosques',\n",
       " 6630: 'crown',\n",
       " 52230: 'culpas',\n",
       " 27657: 'crows',\n",
       " 53347: 'surrell',\n",
       " 52232: 'flowless',\n",
       " 52233: 'sheirk',\n",
       " 40926: \"'three\",\n",
       " 52234: \"peterson'\",\n",
       " 52235: 'ooverall',\n",
       " 40927: 'perchance',\n",
       " 1324: 'bottom',\n",
       " 53366: 'chabert',\n",
       " 52236: 'sneha',\n",
       " 13891: 'inhuman',\n",
       " 52237: 'ichii',\n",
       " 52238: 'ursla',\n",
       " 30601: 'completly',\n",
       " 40928: 'moviedom',\n",
       " 52239: 'raddick',\n",
       " 51998: 'brundage',\n",
       " 40929: 'brigades',\n",
       " 1184: 'starring',\n",
       " 52240: \"'goal'\",\n",
       " 52241: 'caskets',\n",
       " 52242: 'willcock',\n",
       " 52243: \"threesome's\",\n",
       " 52244: \"mosque'\",\n",
       " 52245: \"cover's\",\n",
       " 17640: 'spaceships',\n",
       " 40930: 'anomalous',\n",
       " 27658: 'ptsd',\n",
       " 52246: 'shirdan',\n",
       " 21965: 'obscenity',\n",
       " 30602: 'lemmings',\n",
       " 30603: 'duccio',\n",
       " 52247: \"levene's\",\n",
       " 52248: \"'gorby'\",\n",
       " 25258: \"teenager's\",\n",
       " 5343: 'marshall',\n",
       " 9098: 'honeymoon',\n",
       " 3234: 'shoots',\n",
       " 12261: 'despised',\n",
       " 52249: 'okabasho',\n",
       " 8292: 'fabric',\n",
       " 18518: 'cannavale',\n",
       " 3540: 'raped',\n",
       " 52250: \"tutt's\",\n",
       " 17641: 'grasping',\n",
       " 18519: 'despises',\n",
       " 40931: \"thief's\",\n",
       " 8929: 'rapes',\n",
       " 52251: 'raper',\n",
       " 27659: \"eyre'\",\n",
       " 52252: 'walchek',\n",
       " 23389: \"elmo's\",\n",
       " 40932: 'perfumes',\n",
       " 21921: 'spurting',\n",
       " 52253: \"exposition'\\x85\",\n",
       " 52254: 'denoting',\n",
       " 34743: 'thesaurus',\n",
       " 40933: \"shoot'\",\n",
       " 49762: 'bonejack',\n",
       " 52256: 'simpsonian',\n",
       " 30604: 'hebetude',\n",
       " 34744: \"hallow's\",\n",
       " 52257: 'desperation\\x85',\n",
       " 34745: 'incinerator',\n",
       " 10311: 'congratulations',\n",
       " 52258: 'humbled',\n",
       " 5927: \"else's\",\n",
       " 40848: 'trelkovski',\n",
       " 52259: \"rape'\",\n",
       " 59389: \"'chapters'\",\n",
       " 52260: '1600s',\n",
       " 7256: 'martian',\n",
       " 25259: 'nicest',\n",
       " 52262: 'eyred',\n",
       " 9460: 'passenger',\n",
       " 6044: 'disgrace',\n",
       " 52263: 'moderne',\n",
       " 5123: 'barrymore',\n",
       " 52264: 'yankovich',\n",
       " 40934: 'moderns',\n",
       " 52265: 'studliest',\n",
       " 52266: 'bedsheet',\n",
       " 14903: 'decapitation',\n",
       " 52267: 'slurring',\n",
       " 52268: \"'nunsploitation'\",\n",
       " 34746: \"'character'\",\n",
       " 9883: 'cambodia',\n",
       " 52269: 'rebelious',\n",
       " 27660: 'pasadena',\n",
       " 40935: 'crowne',\n",
       " 52270: \"'bedchamber\",\n",
       " 52271: 'conjectural',\n",
       " 52272: 'appologize',\n",
       " 52273: 'halfassing',\n",
       " 57819: 'paycheque',\n",
       " 20609: 'palms',\n",
       " 52274: \"'islands\",\n",
       " 40936: 'hawked',\n",
       " 21922: 'palme',\n",
       " 40937: 'conservatively',\n",
       " 64010: 'larp',\n",
       " 5561: 'palma',\n",
       " 21923: 'smelling',\n",
       " 13001: 'aragorn',\n",
       " 52275: 'hawker',\n",
       " 52276: 'hawkes',\n",
       " 3978: 'explosions',\n",
       " 8062: 'loren',\n",
       " 52277: \"pyle's\",\n",
       " 6707: 'shootout',\n",
       " 18520: \"mike's\",\n",
       " 52278: \"driscoll's\",\n",
       " 40938: 'cogsworth',\n",
       " 52279: \"britian's\",\n",
       " 34747: 'childs',\n",
       " 52280: \"portrait's\",\n",
       " 3629: 'chain',\n",
       " 2500: 'whoever',\n",
       " 52281: 'puttered',\n",
       " 52282: 'childe',\n",
       " 52283: 'maywether',\n",
       " 3039: 'chair',\n",
       " 52284: \"rance's\",\n",
       " 34748: 'machu',\n",
       " 4520: 'ballet',\n",
       " 34749: 'grapples',\n",
       " 76155: 'summerize',\n",
       " 30606: 'freelance',\n",
       " 52286: \"andrea's\",\n",
       " 52287: '\\x91very',\n",
       " 45882: 'coolidge',\n",
       " 18521: 'mache',\n",
       " 52288: 'balled',\n",
       " 40940: 'grappled',\n",
       " 18522: 'macha',\n",
       " 21924: 'underlining',\n",
       " 5626: 'macho',\n",
       " 19510: 'oversight',\n",
       " 25260: 'machi',\n",
       " 11314: 'verbally',\n",
       " 21925: 'tenacious',\n",
       " 40941: 'windshields',\n",
       " 18560: 'paychecks',\n",
       " 3399: 'jerk',\n",
       " 11934: \"good'\",\n",
       " 34751: 'prancer',\n",
       " 21926: 'prances',\n",
       " 52289: 'olympus',\n",
       " 21927: 'lark',\n",
       " 10788: 'embark',\n",
       " 7368: 'gloomy',\n",
       " 52290: 'jehaan',\n",
       " 52291: 'turaqui',\n",
       " 20610: \"child'\",\n",
       " 2897: 'locked',\n",
       " 52292: 'pranced',\n",
       " 2591: 'exact',\n",
       " 52293: 'unattuned',\n",
       " 786: 'minute',\n",
       " 16121: 'skewed',\n",
       " 40943: 'hodgins',\n",
       " 34752: 'skewer',\n",
       " 52294: 'think\\x85',\n",
       " 38768: 'rosenstein',\n",
       " 52295: 'helmit',\n",
       " 34753: 'wrestlemanias',\n",
       " 16829: 'hindered',\n",
       " 30607: \"martha's\",\n",
       " 52296: 'cheree',\n",
       " 52297: \"pluckin'\",\n",
       " 40944: 'ogles',\n",
       " 11935: 'heavyweight',\n",
       " 82193: 'aada',\n",
       " 11315: 'chopping',\n",
       " 61537: 'strongboy',\n",
       " 41345: 'hegemonic',\n",
       " 40945: 'adorns',\n",
       " 41349: 'xxth',\n",
       " 34754: 'nobuhiro',\n",
       " 52301: 'capitães',\n",
       " 52302: 'kavogianni',\n",
       " 13425: 'antwerp',\n",
       " 6541: 'celebrated',\n",
       " 52303: 'roarke',\n",
       " 40946: 'baggins',\n",
       " 31273: 'cheeseburgers',\n",
       " 52304: 'matras',\n",
       " 52305: \"nineties'\",\n",
       " 52306: \"'craig'\",\n",
       " 13002: 'celebrates',\n",
       " 3386: 'unintentionally',\n",
       " 14365: 'drafted',\n",
       " 52307: 'climby',\n",
       " 52308: '303',\n",
       " 18523: 'oldies',\n",
       " 9099: 'climbs',\n",
       " 9658: 'honour',\n",
       " 34755: 'plucking',\n",
       " 30077: '305',\n",
       " 5517: 'address',\n",
       " 40947: 'menjou',\n",
       " 42595: \"'freak'\",\n",
       " 19511: 'dwindling',\n",
       " 9461: 'benson',\n",
       " 52310: 'white’s',\n",
       " 40948: 'shamelessness',\n",
       " 21928: 'impacted',\n",
       " 52311: 'upatz',\n",
       " 3843: 'cusack',\n",
       " 37570: \"flavia's\",\n",
       " 52312: 'effette',\n",
       " 34756: 'influx',\n",
       " 52313: 'boooooooo',\n",
       " 52314: 'dimitrova',\n",
       " 13426: 'houseman',\n",
       " 25262: 'bigas',\n",
       " 52315: 'boylen',\n",
       " 52316: 'phillipenes',\n",
       " 40949: 'fakery',\n",
       " 27661: \"grandpa's\",\n",
       " 27662: 'darnell',\n",
       " 19512: 'undergone',\n",
       " 52318: 'handbags',\n",
       " 21929: 'perished',\n",
       " 37781: 'pooped',\n",
       " 27663: 'vigour',\n",
       " 3630: 'opposed',\n",
       " 52319: 'etude',\n",
       " 11802: \"caine's\",\n",
       " 52320: 'doozers',\n",
       " 34757: 'photojournals',\n",
       " 52321: 'perishes',\n",
       " 34758: 'constrains',\n",
       " 40951: 'migenes',\n",
       " 30608: 'consoled',\n",
       " 16830: 'alastair',\n",
       " 52322: 'wvs',\n",
       " 52323: 'ooooooh',\n",
       " 34759: 'approving',\n",
       " 40952: 'consoles',\n",
       " 52067: 'disparagement',\n",
       " 52325: 'futureistic',\n",
       " 52326: 'rebounding',\n",
       " 52327: \"'date\",\n",
       " 52328: 'gregoire',\n",
       " 21930: 'rutherford',\n",
       " 34760: 'americanised',\n",
       " 82199: 'novikov',\n",
       " 1045: 'following',\n",
       " 34761: 'munroe',\n",
       " 52329: \"morita'\",\n",
       " 52330: 'christenssen',\n",
       " 23109: 'oatmeal',\n",
       " 25263: 'fossey',\n",
       " 40953: 'livered',\n",
       " 13003: 'listens',\n",
       " 76167: \"'marci\",\n",
       " 52333: \"otis's\",\n",
       " 23390: 'thanking',\n",
       " 16022: 'maude',\n",
       " 34762: 'extensions',\n",
       " 52335: 'ameteurish',\n",
       " 52336: \"commender's\",\n",
       " 27664: 'agricultural',\n",
       " 4521: 'convincingly',\n",
       " 17642: 'fueled',\n",
       " 54017: 'mahattan',\n",
       " 40955: \"paris's\",\n",
       " 52339: 'vulkan',\n",
       " 52340: 'stapes',\n",
       " 52341: 'odysessy',\n",
       " 12262: 'harmon',\n",
       " 4255: 'surfing',\n",
       " 23497: 'halloran',\n",
       " 49583: 'unbelieveably',\n",
       " 52342: \"'offed'\",\n",
       " 30610: 'quadrant',\n",
       " 19513: 'inhabiting',\n",
       " 34763: 'nebbish',\n",
       " 40956: 'forebears',\n",
       " 34764: 'skirmish',\n",
       " 52343: 'ocassionally',\n",
       " 52344: \"'resist\",\n",
       " 21931: 'impactful',\n",
       " 52345: 'spicier',\n",
       " 40957: 'touristy',\n",
       " 52346: \"'football'\",\n",
       " 40958: 'webpage',\n",
       " 52348: 'exurbia',\n",
       " 52349: 'jucier',\n",
       " 14904: 'professors',\n",
       " 34765: 'structuring',\n",
       " 30611: 'jig',\n",
       " 40959: 'overlord',\n",
       " 25264: 'disconnect',\n",
       " 82204: 'sniffle',\n",
       " 40960: 'slimeball',\n",
       " 40961: 'jia',\n",
       " 16831: 'milked',\n",
       " 40962: 'banjoes',\n",
       " 1240: 'jim',\n",
       " 52351: 'workforces',\n",
       " 52352: 'jip',\n",
       " 52353: 'rotweiller',\n",
       " 34766: 'mundaneness',\n",
       " 52354: \"'ninja'\",\n",
       " 11043: \"dead'\",\n",
       " 40963: \"cipriani's\",\n",
       " 20611: 'modestly',\n",
       " 52355: \"professor'\",\n",
       " 40964: 'shacked',\n",
       " 34767: 'bashful',\n",
       " 23391: 'sorter',\n",
       " 16123: 'overpowering',\n",
       " 18524: 'workmanlike',\n",
       " 27665: 'henpecked',\n",
       " 18525: 'sorted',\n",
       " 52357: \"jōb's\",\n",
       " 52358: \"'always\",\n",
       " 34768: \"'baptists\",\n",
       " 52359: 'dreamcatchers',\n",
       " 52360: \"'silence'\",\n",
       " 21932: 'hickory',\n",
       " 52361: 'fun\\x97yet',\n",
       " 52362: 'breakumentary',\n",
       " 15499: 'didn',\n",
       " 52363: 'didi',\n",
       " 52364: 'pealing',\n",
       " 40965: 'dispite',\n",
       " 25265: \"italy's\",\n",
       " 21933: 'instability',\n",
       " 6542: 'quarter',\n",
       " 12611: 'quartet',\n",
       " 52365: 'padmé',\n",
       " 52366: \"'bleedmedry\",\n",
       " 52367: 'pahalniuk',\n",
       " 52368: 'honduras',\n",
       " 10789: 'bursting',\n",
       " 41468: \"pablo's\",\n",
       " 52370: 'irremediably',\n",
       " 40966: 'presages',\n",
       " 57835: 'bowlegged',\n",
       " 65186: 'dalip',\n",
       " 6263: 'entering',\n",
       " 76175: 'newsradio',\n",
       " 54153: 'presaged',\n",
       " 27666: \"giallo's\",\n",
       " 40967: 'bouyant',\n",
       " 52371: 'amerterish',\n",
       " 18526: 'rajni',\n",
       " 30613: 'leeves',\n",
       " 34770: 'macauley',\n",
       " 615: 'seriously',\n",
       " 52372: 'sugercoma',\n",
       " 52373: 'grimstead',\n",
       " 52374: \"'fairy'\",\n",
       " 30614: 'zenda',\n",
       " 52375: \"'twins'\",\n",
       " 17643: 'realisation',\n",
       " 27667: 'highsmith',\n",
       " 7820: 'raunchy',\n",
       " 40968: 'incentives',\n",
       " 52377: 'flatson',\n",
       " 35100: 'snooker',\n",
       " 16832: 'crazies',\n",
       " 14905: 'crazier',\n",
       " 7097: 'grandma',\n",
       " 52378: 'napunsaktha',\n",
       " 30615: 'workmanship',\n",
       " 52379: 'reisner',\n",
       " 61309: \"sanford's\",\n",
       " 52380: '\\x91doña',\n",
       " 6111: 'modest',\n",
       " 19156: \"everything's\",\n",
       " 40969: 'hamer',\n",
       " 52382: \"couldn't'\",\n",
       " 13004: 'quibble',\n",
       " 52383: 'socking',\n",
       " 21934: 'tingler',\n",
       " 52384: 'gutman',\n",
       " 40970: 'lachlan',\n",
       " 52385: 'tableaus',\n",
       " 52386: 'headbanger',\n",
       " 2850: 'spoken',\n",
       " 34771: 'cerebrally',\n",
       " 23493: \"'road\",\n",
       " 21935: 'tableaux',\n",
       " 40971: \"proust's\",\n",
       " 40972: 'periodical',\n",
       " 52388: \"shoveller's\",\n",
       " 25266: 'tamara',\n",
       " 17644: 'affords',\n",
       " 3252: 'concert',\n",
       " 87958: \"yara's\",\n",
       " 52389: 'someome',\n",
       " 8427: 'lingering',\n",
       " 41514: \"abraham's\",\n",
       " 34772: 'beesley',\n",
       " 34773: 'cherbourg',\n",
       " 28627: 'kagan',\n",
       " 9100: 'snatch',\n",
       " 9263: \"miyazaki's\",\n",
       " 25267: 'absorbs',\n",
       " 40973: \"koltai's\",\n",
       " 64030: 'tingled',\n",
       " 19514: 'crossroads',\n",
       " 16124: 'rehab',\n",
       " 52392: 'falworth',\n",
       " 52393: 'sequals',\n",
       " ...}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dental-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "criminal-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "rough-proof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "wanted-turtle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-crossing",
   "metadata": {},
   "source": [
    "### 3-2. 딥러닝 모델 설계 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "comprehensive-revelation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,145\n",
      "Trainable params: 160,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "boring-passport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "intended-forest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 46ms/step - loss: 0.6927 - accuracy: 0.5323 - val_loss: 0.6905 - val_accuracy: 0.7353\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.6884 - accuracy: 0.7528 - val_loss: 0.6820 - val_accuracy: 0.7496\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.6767 - accuracy: 0.7980 - val_loss: 0.6655 - val_accuracy: 0.7805\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.6549 - accuracy: 0.8239 - val_loss: 0.6368 - val_accuracy: 0.8023\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.6179 - accuracy: 0.8488 - val_loss: 0.5956 - val_accuracy: 0.8148\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.5687 - accuracy: 0.8533 - val_loss: 0.5463 - val_accuracy: 0.8214\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.5111 - accuracy: 0.8622 - val_loss: 0.4937 - val_accuracy: 0.8281\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.4520 - accuracy: 0.8631 - val_loss: 0.4474 - val_accuracy: 0.8329\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.3987 - accuracy: 0.8741 - val_loss: 0.4112 - val_accuracy: 0.8381\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.3478 - accuracy: 0.8868 - val_loss: 0.3849 - val_accuracy: 0.8420\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.3163 - accuracy: 0.8920 - val_loss: 0.3671 - val_accuracy: 0.8461\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.2844 - accuracy: 0.9013 - val_loss: 0.3547 - val_accuracy: 0.8502\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.2621 - accuracy: 0.9103 - val_loss: 0.3460 - val_accuracy: 0.8538\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.2410 - accuracy: 0.9177 - val_loss: 0.3402 - val_accuracy: 0.8547\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.2209 - accuracy: 0.9272 - val_loss: 0.3370 - val_accuracy: 0.8567\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.2000 - accuracy: 0.9343 - val_loss: 0.3349 - val_accuracy: 0.8571\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.1906 - accuracy: 0.9348 - val_loss: 0.3340 - val_accuracy: 0.8578\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 0.1753 - accuracy: 0.9434 - val_loss: 0.3344 - val_accuracy: 0.8575\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.1660 - accuracy: 0.9457 - val_loss: 0.3359 - val_accuracy: 0.8569\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 0.1544 - accuracy: 0.9501 - val_loss: 0.3377 - val_accuracy: 0.8566\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "three-highway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.3626 - accuracy: 0.8436\n",
      "[0.3626401424407959, 0.8435999751091003]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "personalized-british",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "japanese-drive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "forty-bacteria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-concept",
   "metadata": {},
   "source": [
    "### 3-3. Word2Vec 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "liquid-flooring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "senior-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "alike-distinction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04264448, -0.04440128, -0.02738497, -0.04179336, -0.03073495,\n",
       "       -0.03354403,  0.00649993, -0.03194995, -0.04034507, -0.03837986,\n",
       "       -0.04042329, -0.02063098, -0.02314546, -0.026734  , -0.01212582,\n",
       "       -0.04332206], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "atlantic-vatican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('especially', 0.9892097115516663),\n",
       " ('lion', 0.9856967329978943),\n",
       " ('knowing', 0.9854108691215515),\n",
       " ('depict', 0.9831366539001465),\n",
       " ('desire', 0.9829800128936768),\n",
       " ('li', 0.9824551939964294),\n",
       " ('chases', 0.982445478439331),\n",
       " ('ruled', 0.981305718421936),\n",
       " ('learns', 0.9809335470199585),\n",
       " ('9', 0.9807727336883545)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "front-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "pretty-speaking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "likely-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "sudden-virus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "positive-northeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 36s 992ms/step - loss: 0.6946 - accuracy: 0.5187 - val_loss: 0.6649 - val_accuracy: 0.6059\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 25s 846ms/step - loss: 0.6412 - accuracy: 0.6403 - val_loss: 0.5460 - val_accuracy: 0.7476\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 25s 847ms/step - loss: 0.4893 - accuracy: 0.7889 - val_loss: 0.3859 - val_accuracy: 0.8392\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 25s 846ms/step - loss: 0.3190 - accuracy: 0.8798 - val_loss: 0.3384 - val_accuracy: 0.8535\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 25s 848ms/step - loss: 0.2469 - accuracy: 0.9055 - val_loss: 0.3373 - val_accuracy: 0.8541\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 25s 847ms/step - loss: 0.1822 - accuracy: 0.9377 - val_loss: 0.3077 - val_accuracy: 0.8726\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 25s 849ms/step - loss: 0.1346 - accuracy: 0.9600 - val_loss: 0.3165 - val_accuracy: 0.8729\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 25s 848ms/step - loss: 0.1046 - accuracy: 0.9703 - val_loss: 0.3181 - val_accuracy: 0.8734\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 25s 847ms/step - loss: 0.0720 - accuracy: 0.9857 - val_loss: 0.3429 - val_accuracy: 0.8707\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 25s 848ms/step - loss: 0.0543 - accuracy: 0.9907 - val_loss: 0.3494 - val_accuracy: 0.8735\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 25s 849ms/step - loss: 0.0383 - accuracy: 0.9960 - val_loss: 0.3748 - val_accuracy: 0.8706\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 25s 848ms/step - loss: 0.0252 - accuracy: 0.9983 - val_loss: 0.3810 - val_accuracy: 0.8712\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 25s 847ms/step - loss: 0.0176 - accuracy: 0.9989 - val_loss: 0.4065 - val_accuracy: 0.8718\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 25s 847ms/step - loss: 0.0123 - accuracy: 0.9996 - val_loss: 0.4331 - val_accuracy: 0.8704\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 25s 847ms/step - loss: 0.0091 - accuracy: 0.9996 - val_loss: 0.4641 - val_accuracy: 0.8668\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 25s 847ms/step - loss: 0.0062 - accuracy: 0.9998 - val_loss: 0.4756 - val_accuracy: 0.8720\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 25s 846ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.4940 - val_accuracy: 0.8716\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 25s 846ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.5098 - val_accuracy: 0.8709\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 25s 848ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.8705\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 25s 846ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5387 - val_accuracy: 0.8705\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "amended-paraguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 16s - loss: 0.5915 - accuracy: 0.8572\n",
      "[0.5914715528488159, 0.8572400212287903]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
